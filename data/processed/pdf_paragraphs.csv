document,page,text,cleaned_text
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",purpose this article provides guidance regarding employees contractors volunteers or other persons performing role for salt lake city use of generative artificial intelligence ai for city business and or when using city resources
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",definitions artificial intelligence ai machine based system that can for given set of human defined objectives make predictions recommendations or decisions influencing real or virtual environments artificial intelligence systems use machine and human based inputs to perceive real and virtual environments abstract such perceptions into models through analysis in an automated manner and use model inference to formulate options for information or action
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",artificial intelligence system any system software sensor or process that automatically generates outputs including but not limited to predictions recommendations or decisions that augment or replace human decision making this extends to software hardware algorithms and data generated by these systems used to automate large scale processes or analyze large data sets
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",compliant artificial intelligence platform generative artificial intelligence platform that the city obtained through an approved procurement process satisfies all the requirements of privacy impact assessment conducted by the city and complies with all the rules and safeguards set forth in title chapter security information technology
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",generative artificial intelligence branch of ai technology that can generate content such as generating business letters and other documents that present an argument summarize information or analyze information like survey results at the request of user salt lake city recognizes the opportunity for controlled and responsible approach that acknowledges the benefits to efficiency while minimizing the risks around ai bias privacy and cybersecurity
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",users employees contractors volunteers or other persons performing role for salt lake city use of generative artificial intelligence for city business and or when using city resources
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",scope this article applies to all use of generative ai by users
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",responsibilities usage of generative ai shall follow salt lake city ai principles
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",privacy unless the generative ai tool at issue is compliant artificial intelligence platform as described in section only submit information to generative ai tools that is ready for public disclosure this includes any text photos videos or voice recordings shared with the ai be mindful that the ai output may include unexpected personal information from another user so users must remove any potentially private information before publishing
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",anything that would not be released or shared with the public should not be inputted into the ai tools this includes protected private or controlled records and information such as draft request for proposal requirements that should not be public yet vendor transactions procurement approvals or internal city decisions
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",general rule if the information exchanged with generative ai system would be harmful to person or community if made public it is high or intolerable risk services can be compromised and leak personal information all information exchanged with generative ai has reasonable risk of being compromised if unsure do not input into generative ai
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",mid risk information includes non identifying and non confidential information for example simple email response or instructive documents often contain only general information that would not present any risk if made public
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",high risk information includes personally identifiable information full name birth date email address and confidential business information that may have larger implications to city processes
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",prohibited risk information includes highly sensitive and identifying information this includes data such as credit card numbers bank account information social security numbers and other information that requires rigorous security measures and compliance standards before being processed
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",accuracy salt lake city maintains trust with its constituents by providing accurate information review and fact check all outputs received from generative ai users should consult trustworthy sources to confirm that the facts and details in the ai generated content are accurate be aware that many systems may only use information up to certain date and cannot guarantee the content they generate is accurate
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",trustworthy sources include city reports records master plans codes policies and department division webpages city staff should also consult their manager department director or division leadership to verify the accuracy of information
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",transparency the user shall be clear when they use generative ai this includes citing that ai was used in creating product
SaltLakeCity.pdf,1,"ARTICLE E. USE OF GENERATIVE ARTIFICIAL INTELLIGENCE

52-13E-1: PURPOSE:
This article provides guidance regarding employees, contractors, volunteers, or other persons performing a role for Salt Lake
City use of generative artificial intelligence (AI) for City business and/or when using City resources.

52-13E-2: DEFINITIONS:
ARTIFICIAL INTELLIGENCE(AI): Machine-based system that can, for a given set of human-defined objectives, make
predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use
machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through
analysis in an automated manner; and use model inference to formulate options for information or action.

ARTIFICIAL INTELLIGENCE SYSTEM: Any system, software, sensor, or process that automatically generates outputs
including, but not limited to, predictions, recommendations, or decisions that augment or replace human decision-making.
This extends to software, hardware, algorithms, and data generated by these systems, used to automate large-scale
processes or analyze large data sets.

COMPLIANT ARTIFICIAL INTELLIGENCE PLATFORM: a generative artificial intelligence platform that (i) the City obtained
through an approved procurement process; (ii) satisfies all the requirements of a Privacy Impact Assessment conducted by
the City; and (iii) complies with all the rules and safeguards set forth in Title 52, Chapter 5 “Security (Information
Technology)”

GENERATIVE ARTIFICIAL INTELLIGENCE: Branch of AI technology that can generate content—such as generating
business letters and other documents that present an argument, summarize information, or analyze information like survey
results — at the request of a user. Salt Lake City recognizes the opportunity for a controlled and responsible approach that
acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity.

USERS: Employees, contractors, volunteers, or other persons performing a role for Salt Lake City use of generative artificial
intelligence for City business and/or when using City resources.

52-13E-3: SCOPE:
This article applies to all use of generative AI by Users.

52-13E-4: RESPONSIBILITIES:
Usage of generative AI shall follow Salt Lake City’s AI principles:

   A.   Privacy: Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in section 52-
13E-2, only submit information to generative AI tools that is ready for public disclosure. This includes any text, photos,
videos, or voice recordings shared with the AI. Be mindful that the AI output may include unexpected personal information
from another user, so users must remove any potentially private information before publishing.

      a.   Anything that would not be released or shared with the public should not be inputted into the AI tools. This includes
protected, private, or controlled records, and information such as draft Request for Proposal requirements that should not be
public yet, vendor transactions, procurement approvals, or internal City decisions.

      b.   General rule: If the information exchanged with a Generative AI system would be harmful to a person or community if
made public, it is a high or intolerable risk. Services can be compromised and leak personal information, all information
exchanged with Generative AI has a reasonable risk of being compromised. If unsure, do not input into Generative AI.

      c.   Mid-risk information includes non-identifying and non-confidential information. For example, a simple email
response or instructive documents often contain only general information that would not present any risk if made public.

      d.   High-risk information includes personally identifiable information (e.g., full name, birth date, email address) and
confidential business information that may have larger implications to City processes.

      e.   Prohibited risk information includes highly sensitive and identifying information. This includes data such as
credit card numbers, bank account information, social security numbers, and other information that requires rigorous security
measures and compliance standards before being processed.

   B.   Accuracy: Salt Lake City maintains trust with its constituents by providing accurate information. Review and fact check
all outputs received from a generative AI. Users should consult trustworthy sources to confirm that the facts and details in
the AI-generated content are accurate. Be aware that many systems may only use information up to a certain date and
cannot guarantee the content they generate is accurate.

      a.   Trustworthy sources include City reports, records, master plans, codes, policies, and department/division webpages.
City staff should also consult their manager, department director or division leadership to verify the accuracy of information.

   C.   Transparency: The user shall be clear when they use generative AI. This includes citing that AI was used in creating a
product.

   D.   Equity: AI system responses are based on patterns and relationships learned from large datasets derived from existing
human knowledge, which may contain errors and may be historically biased across race, sex, gender identity, ability, and
many other factors. Users of generative AI must be mindful of any assumptions generative AI may make based on past

",equity ai system responses are based on patterns and relationships learned from large datasets derived from existing human knowledge which may contain errors and may be historically biased across race sex gender identity ability and many other factors users of generative ai must be mindful of any assumptions generative ai may make based on past
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",stereotypes users must edit or disregard biased output
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",accountability the person using ai is accountable for the content it generates use generative ai with healthy dose of skepticism the level of caution used should correspond to the risk level of the use case it is always important to verify information provided by generative ai
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",beneficial users should be open to responsibly incorporating generative ai into their work where it can make services better more just and more efficient
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",privacy opt out some services offer an option to opt out of data collection this means the generative ai system will not keep the data you provide and it will not be used in the system models salt lake city as customer of ai products shall opt out of data collection and model training whenever possible
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",verify the copyright of all generated content users shall verify the content they use from any generative ai systems does not infringe any copyright laws if users are uncertain if content violates copyright they should either edit the content to be original or not use it
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",visit the copyright office to learn if content is copyrighted db local page first
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",ownership of generated content in most cases the user owns the content they input into generative ai service and the information they receive as an output the user can use the content at their discretion in accordance with salt lake city policy and any terms and conditions they agreed to with the generative ai software however many generative ai companies still retain the right to use both the input and output content for their own commercial purposes for example this could include generative ai company using salt lake city data to train their models or distributing salt lake city output data for marketing campaigns this emphasizes the importance that only information salt lake city is ready to make public should be entered into generative ai system
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",use of generative ai users are required to follow these rules while using generative ai for salt lake city work
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",information you enter into generative ai systems could be subject to government records access and management act grama request is record requiring retention considerations may be viewable and usable by the city and may be leaked in data breach unless the generative ai tool at issue is compliant artificial intelligence platform as described in section do not submit any information to generative ai platform that would not be available to the general public such as confidential protected or personally identifiable information
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",thoroughly review revise and fact check any output from generative ai users are responsible for any material created with ai support
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",users must cite the generative ai when substantial portion of the content used in the final version comes from the generative ai
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",users may not utilize city generative ai accounts for personal use and users may not utilize personal generative ai accounts for official city business
SaltLakeCity.pdf,2,"stereotypes. Users must edit or disregard biased output.

   E.   Accountability: The person using AI is accountable for the content it generates. Use generative AI with a healthy dose
of skepticism. The level of caution used should correspond to the risk level of the use case. It is always important to verify
information provided by generative AI.

   F.   Beneficial: Users should be open to responsibly incorporating generative AI into their work where it can make services
better, more just, and more efficient.

52-13E-5: PRIVACY
   A.   Opt Out: Some services offer an option to opt out of data collection. This means the generative AI system will not
keep the data you provide, and it will not be used in the system’s models. Salt Lake City as a customer of AI products, shall
opt out of data collection and model training whenever possible.

   B.   Verify the Copyright of All Generated Content: Users shall verify the content they use from any generative AI systems
does not infringe any copyright laws. If users are uncertain if content violates copyright, they should either edit the content to
be original or not use it.

      a.   Visit the U.S. Copyright Office to learn if content is copyrighted: https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?
DB=local&PAGE=First

   C.   Ownership of Generated Content: In most cases, the user owns the content they input into a generative AI service
and the information they receive as an output. The user can use the content at their discretion, in accordance with Salt Lake
City policy and any terms and conditions they agreed to with the generative AI software. However, many generative AI
companies still retain the right to use both the input and output content for their own commercial purposes. For example, this
could include a generative AI company using Salt Lake City data to train their models or distributing Salt Lake City output
data for marketing campaigns. This emphasizes the importance that only information Salt Lake City is ready to make public
should be entered into a generative AI system.

52-13E-6: USE OF GENERATIVE AI
Users are required to follow these rules while using generative AI for Salt Lake City work:

   A.   Information you enter into generative AI systems could be subject to a Government Records Access and Management
Act (GRAMA) request, is a record requiring retention considerations, may be viewable and usable by the City, and may be
leaked in a data breach. Unless the generative AI tool at issue is a Compliant Artificial Intelligence Platform as described in
section 52-13E-2, do not submit any information to a generative AI platform that would not be available to the general public
(such as confidential, protected or personally identifiable information).

   B.   Thoroughly review, revise, and fact check any output from generative AI. Users are responsible for any material
created with AI support.

   C.   Users must cite the generative AI when a substantial portion of the content used in the final version comes from the
generative AI.

   D.   Users may not utilize City generative AI accounts for personal use and users may not utilize personal generative AI
accounts for official City business.

(Adopted December 2024)

",adopted december
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",intelligence ai information technology department itd november
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",purpose of these guidelines
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",the purpose of these guidelines is to help city of cambridge employees use generative ai tools safely responsibly and effectively the guidelines provide direction on what generative ai is best practices on how it should be used responsibly and how to protect data privacy and security this is living document and itd will regularly update the guidelines to reflect evolving laws regulations lessons learned and developments in generative ai technology
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",generative ai is new type of artificial intelligence technology that can create new content such as text images video audio or code based on prompts or inputs from users these tools analyze patterns in large datasets to predict and produce relevant outputs common examples include chat gpt microsoft copilot google gemini and claude
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",while generative ai has the potential to enhance our work and better serve our community it also poses risks these include bias misinformation hallucinations factual errors copyright violations and inconsistent outputs these risks are heightened when employees rely on these tools without exercising the necessary human oversight
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",who should follow these guidelines
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",all employees volunteers contractors vendors and anyone representing or working on behalf of the city of cambridge
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",important considerations for generative ai use
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",accuracy reliability
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",human must always thoroughly review edit fact check validate and test their ai
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",generated content before official use ai tools can make mistakes or provide outdated information you are ultimately responsible for any content you use or share
Cambridge.pdf,1,"City of Cambridge Guidelines on Using Generative Artificial 
Intelligence (AI)  
Information Technology Department (ITD) | November 3, 2025 

Purpose of These Guidelines 

The purpose of these guidelines is to help City of Cambridge employees use Generative AI 
tools safely, responsibly, and effectively. The guidelines provide direction on what 
Generative AI is, best practices on how it should be used responsibly, and how to protect 
data privacy and security. This is a living document and ITD will regularly update the 
Guidelines to reflect evolving laws, regulations, lessons learned, and developments in 
Generative AI technology.  

Generative AI is a new type of artificial intelligence technology that can create new 
content—such as text, images, video, audio, or code—based on prompts or inputs from 
users. These tools analyze patterns in large datasets to predict and produce relevant 
outputs. Common examples include ChatGPT, Microsoft Copilot, Google Gemini, and 
Claude. 

While Generative AI has the potential to enhance our work and better serve our community 
it also poses risks. These include bias, misinformation, hallucinations, factual errors, 
copyright violations, and inconsistent outputs. These risks are heightened when employees 
rely on these tools without exercising the necessary human oversight.  

Who Should Follow These Guidelines? 

All employees, volunteers, contractors, vendors, and anyone representing or working on 
behalf of the City of Cambridge.  

Important Considerations for Generative AI Use 

1.  Accuracy & Reliability 

•  A human must always thoroughly review, edit, fact-check, validate and test their AI-

generated content before official use. AI tools can make mistakes or provide 
outdated information. You are ultimately responsible for any content you use or 
share. 

2.  Data Security & Privacy 

1 

 
",data security privacy
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",only use city approved authorized ai tools for sensitive or confidential data personally identifiable information pii or protected health information phi
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",personally identifying information pii means person first name and last name or first initial and last name in combination with any one or more of the following data elements that relate to such person
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",social security number driver license number or state issued identification card number or financial account number credit or debit card number with or without any required security code access code personal identification number or password that would permit access to person financial account it does not include information that may be obtained from publicly available information or from federal state or local government records lawfully made available to the general public
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",if you are unsure whether data is appropriate to input into city approved or other generative ai tool you can contact itd helpdesk or
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",always adhere to the city written information security policy wisp guidelines
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",when handling sensitive data
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",bias fairness
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",ai can unintentionally reflect biases from its training data be attentive to potential unfairness or inaccuracies particularly in content affecting community services policies or communications regularly review outputs to ensure fairness and accuracy
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",transparency accountability
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",transparency builds public trust and helps colleagues learn how to use generative
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",ai responsibly expectations on citations may vary by the type of work
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",low risk internal uses no citation required
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",for routine internal tasks you are not required to cite or document your use of
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",generative ai examples include
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",drafting internal emails memos or communications
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",creating summaries of internal documents
Cambridge.pdf,2,"Only use City-approved, authorized AI tools for sensitive or confidential data- Personally 
Identifiable Information (PII) or Protected Health Information (PHI). 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

• 

If you are unsure whether data is appropriate to input into a City-approved or other 
Generative AI tool, you can contact ITD Helpdesk or 617-349-4140. 

•  Always adhere to the City’s Written Information Security Policy (WISP) guidelines 

when handling sensitive data.  

3.  Bias & Fairness 

•  AI can unintentionally reflect biases from its training data. Be attentive to potential 
unfairness or inaccuracies, particularly in content affecting community services, 
policies, or communications. Regularly review outputs to ensure fairness and 
accuracy. 

4.  Transparency & Accountability 

•  Transparency builds public trust and helps colleagues learn how to use Generative 

AI responsibly. Expectations on citations may vary by the type of work: 

Low-Risk Internal Uses (No Citation Required) 

•  For routine, internal tasks, you are not required to cite or document your use of 

Generative AI. Examples include: 

i.  Drafting internal emails, memos, or communications 

ii.  Creating summaries of internal documents 

iii.  Writing, editing, or debugging code you can validate 

2 

 
",writing editing or debugging code you can validate
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",recommended practice to improve team learning and safe use you are
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",encouraged to share how you used ai such as prompts or edits made even when citation is not required
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",medium to high risk uses documentation required
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",for public facing or sensitive work you must document and disclose your use of
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",generative ai examples include
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",drafting or translating public facing content
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",summarizing policy related or public input data
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",supporting decisions related to services enforcement or eligibility
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",contributing to documents that affect regulation safety or compliance
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",requirements
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",clearly indicate when ai significantly contributed to the content include
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",statement that generative ai was used
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",the name and version of the tool
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",note that the content was reviewed and
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",sample credit line this description was generated summarized with the assistance of tool name and reviewed by city staff
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",prohibited practice
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",generative ai should never be relied upon to create official city documents or to make decisions that affect residents without expert human review and approval
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",users should be aware that ai generated content including prompts and outputs is subject to public records law and may be considered public record therefore use of generative ai must be properly managed and retained by the employee in accordance with all applicable policies and laws of the city and commonwealth
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",choosing using ai tools
Cambridge.pdf,3,"•  Recommended Practice: To improve team learning and safe use, you are 

encouraged to share how you used AI—such as prompts or edits made—even when 
citation is not required. 

Medium- to High-Risk Uses (Documentation Required) 

•  For public-facing or sensitive work, you must document and disclose your use of 

Generative AI. Examples include: 

i.  Drafting or translating public-facing content 

ii. 

iii. 

Summarizing policy-related or public input data 

Supporting decisions related to services, enforcement, or eligibility 

iv.  Contributing to documents that affect regulation, safety, or compliance 

•  Requirements: 

i.  Clearly indicate when AI significantly contributed to the content. Include: 

a.  A statement that Generative AI was used 

b.  The name and version of the tool 

c.  A note that the content was reviewed and approved by City staff 

ii. 

Sample Credit Line: “This description was generated/summarized with 
the assistance of [Tool Name] and reviewed by City staff.” 

Prohibited Practice 

•  Generative AI should never be relied upon to create official City documents or to 
make decisions that affect residents without expert human review and approval. 

•  Users should be aware that AI-generated content (including prompts and 
outputs) is subject to public records law and may be considered a public 
record. Therefore, use of Generative AI must be properly managed and retained 
by the employee in accordance with all applicable policies and laws of the City 
and Commonwealth.  

Choosing & Using AI Tools 

•  City-Approved Tools: You are encouraged to use City-approved Generative AI tools.  
Only use City-approved tools for sensitive or confidential data. These tools have 
been vetted for security, privacy, and appropriate use.   

3 

 
",city approved tools you are encouraged to use city approved generative ai tools only use city approved tools for sensitive or confidential data these tools have been vetted for security privacy and appropriate use
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",copilot chat microsoft generative ai chatbot is available to city employees if you log into microsoft copilot with your city account credentials data you enter or extract from the model will not be used to train the underlying models
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",requesting new tools to request an ai tool not currently approved submit
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",request through the itd helpdesk or appropriate technology procurement channels like egov process all technology acquisitions including free to use software or software as service tools must comply with the city procurement and it standards and policies
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",public generative ai tools these include free paid or publicly available chatbots or apps not procured or managed by the city these tools do not offer adequate privacy or security protections for sensitive or confidential data any information shared with them may be used to train the underlying models creating potential confidentiality risks
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",while the use of public or consumer generative ai tools for city business is discouraged we recognize that such tools may still be used in limited non sensitive low risk circumstances any such use must follow the guidance in this document and should never involve confidential personal or regulated information
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",itd oversight itd may revoke approval of an ai tool if it is found to pose unacceptable risks
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",your responsibilities
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",employees use ai responsibly ensure outputs are human reviewed and report any misuse or concerns you are ultimately responsible for your work including content generated by an ai model you should thoroughly review ai outputs for accuracy and appropriateness of responses
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",managers and department heads provide guidance on responsible ai use ensure
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",your team follows these guidelines and address any inappropriate use of ai
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",itd staff assist employees with training using secure and approved ai tools and oversee tool management
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",itd cybersecurity team ensure ai use and tools are compliant with city security policies and oversee ai tool evaluations
Cambridge.pdf,4,"o  Copilot Chat, a Microsoft Generative AI chatbot, is available to City 
employees. If you log into Microsoft’s Copilot with your City account 
credentials, data you enter or extract from the model will not be used to train 
the underlying models.   

•  Requesting New Tools: To request an AI tool not currently approved, submit a 

request through the ITD Helpdesk or appropriate technology procurement channels 
(like Egov process). All technology acquisitions, including free-to-use software or 
software-as-a-service tools, must comply with the City’s procurement and IT 
standards and policies. 

•  Public Generative AI tools: These include free, paid, or publicly available chatbots 
or apps not procured or managed by the City. These tools do not offer adequate 
privacy or security protections for sensitive or confidential data. Any information 
shared with them may be used to train the underlying models, creating potential 
confidentiality risks. 

o  While the use of public or consumer Generative AI tools for City business is 
discouraged, we recognize that such tools may still be used in limited non-
sensitive, low-risk circumstances. Any such use must follow the guidance in 
this document and should never involve confidential, personal, or regulated 
information.  

• 

ITD Oversight: ITD may revoke approval of an AI tool if it is found to pose 
unacceptable risks. 

Your Responsibilities 

•  Employees: Use AI responsibly, ensure outputs are human reviewed, and report any 
misuse or concerns. You are ultimately responsible for your work, including 
content generated by an AI model. You should thoroughly review AI outputs for 
accuracy and appropriateness of responses.  

•  Managers and Department Heads: Provide guidance on responsible AI use, ensure 

your team follows these guidelines, and address any inappropriate use of AI. 

• 

• 

ITD Staff: Assist employees with training, using secure and approved AI tools, and 
oversee tool management. 

ITD Cybersecurity Team: Ensure AI use and tools are compliant with City security 
policies and oversee AI tool evaluations. 

Relevant City Policies & Practices 

4 

 
",relevant city policies practices
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",city of cambridge written information security policy wisp
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",city of cambridge computer use policy
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",contact versioning
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",this is living document and itd will regularly update the guidelines to reflect evolving laws regulations lessons learned and developments in generative ai technology
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",for questions please reach out to the itd helpdesk or call
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",this report includes content drafted with support from microsoft co pilot all content was reviewed and finalized by the itd team
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",glossary
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",artificial intelligence ai broad category of technologies that can perform tasks that typically require human intelligence such as recognizing patterns making predictions or understanding language by analyzing large amounts of data
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",generative ai gen ai type of ai that creates new content such as text images code or audio based on user prompts using patterns it has learned from large datasets
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",hallucinations are false misleading or fabricated outputs produced by ai tools
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",that appear credible but are not based on real or accurate information
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",personally identifying information pii means person first name and last name or first initial and last name in combination with any one or more of the following data elements that relate to such person
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",social security number driver license number or state issued identification card number or financial account number credit or debit card number with or without any required security code access code personal identification number or password that would permit access to person financial account it does not include information that may be obtained from publicly available information or from federal state or local government records lawfully made available to the general public
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",protected health information phi means any health or medical information that
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",is created or received by an entity and can be linked to specific person phi includes information that relates to
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",person health condition past present or future the health care or treatment person has received or the payment for that care
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",examples include
Cambridge.pdf,5,"•  City of Cambridge Written Information Security Policy (WISP) 

•  City of Cambridge Computer Use Policy 

Contact & Versioning 

This is a living document and ITD will regularly update the Guidelines to reflect evolving 
laws, regulations, lessons learned, and developments in Generative AI technology.  

For questions please reach out to the ITD Helpdesk or call 617-349-4140.  

This report includes content drafted with support from Microsoft 365 CoPilot. All content 
was reviewed and finalized by the ITD team.  

Glossary 

•  Artificial Intelligence (AI): a broad category of technologies that can perform tasks 
that typically require human intelligence—such as recognizing patterns, making 
predictions, or understanding language—by analyzing large amounts of data. 

•  Generative AI (Gen AI): a type of AI that creates new content (such as text, images, 
code, or audio) based on user prompts, using patterns it has learned from large 
datasets.  

•  Hallucinations: are false, misleading, or fabricated outputs produced by AI tools 

that appear credible but are not based on real or accurate information. 

•  Personally Identifying Information (PII): means a person’s first name and last 
name, or first initial and last name, in combination with any one or more of the 
following data elements that relate to such person:  

o  Social Security Number 
o  Driver’s license number or state issued identification card number; or 
o  Financial account number, credit or debit card number with or without any 
required security code, access code, personal identification number or 
password, that would permit access to a person’s financial account.  
It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

o 

•  Protected Health Information (PHI): means any health or medical information that 

is created or received by an entity and can be linked to a specific person. PHI 
includes information that relates to: 

o  A person’s health condition (past, present, or future); 
o  The health care or treatment a person has received; or 
o  The payment for that care. 

Examples include: 

o  Medical record or patient ID numbers 
o  Health insurance or subscriber numbers 

5 

 
",medical record or patient id numbers health insurance or subscriber numbers
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",test results diagnoses or treatment details prescription information bills or claims that include person name or health details
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",it does not include information that may be obtained from publicly available information or from federal state or local government records lawfully made available to the general public
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",quick guide
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",category
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",do
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",accuracy reliability
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",thoroughly review edit and fact check all ai outputs before use
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",data security privacy
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",only use city approved tools such as microsoft copilot for sensitive or confidential data personally identifiable information pii or protected health information phi and comply with the city written information security program wisp
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",don
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",share or publish ai generated content without human review
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",enter personally identifiable information or protected health information into non approved ai tools
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",bias fairness
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",check outputs for fairness accuracy and inclusivity
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",rely on ai outputs that may be unfair or inaccurate
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",transparency accountability
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",disclose when public facing or sensitive work is ai generated or ai assisted to maintain public trust
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",present ai generated content in public facing or sensitive work as entirely your own without acknowledgment
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",public records
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",save prompts and ai outputs used for city business as public records per wisp
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",delete or fail to retain ai generated work that qualifies as public record
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",tool selection
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",employees are encouraged to use city approved tools or request new ones via the itd helpdesk while the use of non approved tools is discouraged we recognize that such tools may still be
Cambridge.pdf,6,"o  Test results, diagnoses, or treatment details 
o  Prescription information 
o  Bills or claims that include a person’s name or health details 
o 

It does not include information that may be obtained from publicly available 
information or from federal, state or local government records lawfully made 
available to the general public.  

Quick Guide 

Category 

Do 

Accuracy & 
Reliability 

Thoroughly review, edit, and fact-check 
all AI outputs before use. 

Data Security & 
Privacy 

Only use City-approved tools (such as 
Microsoft Copilot) for sensitive or 
confidential data- Personally 
Identifiable Information (PII) or 
Protected Health Information (PHI)- and 
comply with the City’s Written 
Information Security Program (WISP).  

Don’t 

Share or publish AI-generated 
content without human 
review. 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

Bias & Fairness 

Check outputs for fairness, accuracy, 
and inclusivity. 

Rely on AI outputs that may be 
unfair or inaccurate. 

Transparency & 
Accountability 

Disclose when public facing or sensitive 
work is AI-generated or AI-assisted to 
maintain public trust. 

Present AI-generated content 
in public facing or sensitive 
work as entirely your own 
without acknowledgment. 

Public Records 

Save prompts and AI outputs used for 
City business as public records per 
WISP. 

Delete or fail to retain AI-
generated work that qualifies 
as a public record. 

Tool Selection 

Employees are encouraged to use City-
approved tools or request new ones via 
the ITD Helpdesk. While the use of non- 
approved tools is discouraged, we 
recognize that such tools may still be 

Enter Personally Identifiable 
Information or Protected 
Health Information into non-
approved AI tools. 

6 

 
",enter personally identifiable information or protected health information into non approved ai tools
Cambridge.pdf,7,"used in limited non-sensitive, low-risk 
circumstances. 

Employees: Use responsibly & 
thoroughly review outputs. You are 
ultimately responsible for your work. 
Managers: Monitor team compliance via 
regular checks.                                             
ITD: Provide oversight & training. 

Assume AI tools replace 
human judgment or 
responsibility. 

Responsibilities 

7 

 
 
",used in limited non sensitive low risk circumstances
Cambridge.pdf,7,"used in limited non-sensitive, low-risk 
circumstances. 

Employees: Use responsibly & 
thoroughly review outputs. You are 
ultimately responsible for your work. 
Managers: Monitor team compliance via 
regular checks.                                             
ITD: Provide oversight & training. 

Assume AI tools replace 
human judgment or 
responsibility. 

Responsibilities 

7 

 
 
",employees use responsibly thoroughly review outputs you are ultimately responsible for your work managers monitor team compliance via regular checks itd provide oversight training
Cambridge.pdf,7,"used in limited non-sensitive, low-risk 
circumstances. 

Employees: Use responsibly & 
thoroughly review outputs. You are 
ultimately responsible for your work. 
Managers: Monitor team compliance via 
regular checks.                                             
ITD: Provide oversight & training. 

Assume AI tools replace 
human judgment or 
responsibility. 

Responsibilities 

7 

 
 
",assume ai tools replace human judgment or responsibility
Cambridge.pdf,7,"used in limited non-sensitive, low-risk 
circumstances. 

Employees: Use responsibly & 
thoroughly review outputs. You are 
ultimately responsible for your work. 
Managers: Monitor team compliance via 
regular checks.                                             
ITD: Provide oversight & training. 

Assume AI tools replace 
human judgment or 
responsibility. 

Responsibilities 

7 

 
 
",responsibilities
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",generative ai guidance
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",introduction
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",generative artificial intelligence gen ai systems have become increasingly popular and prevalent in all areas of society today the city recognizes the opportunity for guided and responsible approach to using gen ai that acknowledges the benefits to our efficiency while minimizing the risks around ai bias privacy and cybersecurity
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",gen ai can serve as an exploratory personal assistant tool that can enhance our productivity and support essential city tasks and as such we encourage individual city staff use of gen ai to enhance productivity however in this guidance we provide important guardrails intended to minimize risks and share list of approved and explicitly prohibited ai systems
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",we advise users to protect city and personal information at all times avoid over reliance on the technology to limit the environmental impacts of gen ai use and not to use it to support critical processes until the city develops further policies this guidance is intended to govern gen ai only ai systems that specifically generate content not traditional ai systems at large refer to the definitions section below for details
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",summary
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",we recommend that you use ms copilot chat the city approved gen ai
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",system for enhancing daily productivity to gain access to it you must complete training and sign this acknowledgement form
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",do not submit sensitive city information or private information of any
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",individual or entity to gen ai systems under review such as chat gpt google gemini or claude
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",carefully review verify and fact check via multiple sources the content
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",generated by any gen ai system
LongBeach.pdf,1,"Generative AI Guidance 

V 1.3 

Introduction  

Generative Artificial Intelligence (Gen AI) systems have become increasingly popular and 
prevalent in all areas of society today. The City recognizes the opportunity for a guided and 
responsible approach to using Gen AI that acknowledges the benefits to our efficiency 
while minimizing the risks around AI bias, privacy, and cybersecurity.  

Gen AI can serve as an exploratory “personal assistant” tool that can enhance our 
productivity and support essential City tasks, and as such, we encourage individual City 
staff use of Gen AI to enhance productivity. However, in this Guidance, we provide 
important guardrails intended to minimize risks and share a list of approved and 
explicitly prohibited AI systems.  

We advise users to protect City and personal information at all times, avoid over-reliance 
on the technology to limit the environmental impacts of Gen AI use, and not to use it to 
support critical processes until the City develops further policies. This Guidance is intended 
to govern Gen AI only – AI systems that specifically generate content, not traditional AI 
systems at large. Refer to the “Definitions” section below for details. 

Summary 

I.  We recommend that you use MS Copilot Chat, the City’s approved, Gen AI 

system for enhancing daily productivity. To gain access to it, you must complete 
training and sign this acknowledgement form. 

II.  Do not submit sensitive City information or private information of any 

individual or entity to Gen AI systems under review, such as ChatGPT, Google 
Gemini, or Claude.  

III.  Carefully review, verify, and fact-check via multiple sources the content 

generated by any Gen AI system. 

IV.  Do not use AI meeting assistants (other than transcription functionality provided 
within MS Teams) and request that external collaborators turn off these tools in 
meetings with you.  
If you are considering negotiating a contract with a Gen AI provider or using a 
Gen AI tool not mentioned in this Guidance, you must contact TID.  

V. 

1 

 
 
 
 
 
 
",do not use ai meeting assistants other than transcription functionality provided within ms teams and request that external collaborators turn off these tools in meetings with you if you are considering negotiating contract with gen ai provider or using gen ai tool not mentioned in this guidance you must contact tid
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",approved gen ai systems
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",systems the city of long beach approves the use of ms copilot chat the city enterprise gen ai system for use cases related to enhancing staff productivity you can access it by going to copilot com and logging in with your longbeach gov account visit the ti intranet site for more information the city also approves the use of ms teams for ai powered meeting transcription
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",requirements for use
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",you must complete training and sign this acknowledgement form in order to
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",activate ms copilot chat in your browser
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",you must adhere to the general guidelines specified below
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",rationale ms copilot chat adheres to the same data protection standards as other enterprise microsoft services like share point and ms teams therefore you can safely input city information into it when devising your prompts this is significant advantage of using ms copilot chat over other gen ai systems under review such as chat gpt google gemini or claude
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",staff can use ai powered transcription functionality offered in ms teams but we ask that you turn off the transcription when discussing sensitive and or private information this is because transcription functionality offered through ms teams is subject to public requests act pra requests and we want to avoid the risk of inaccurate or misleading and sensitive information entering the public record
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",prohibited ai systems
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",systems the following ai systems are forbidden to use deepseek otter ai and read ai as well as other ai meeting assistants such as atlas avoma click up colibri compas dubber fathom fireflies ai gong grain laxis meet record meet geek read ai sembly and zoom ai
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",requirements for use these systems are forbidden
LongBeach.pdf,2,"City of Long Beach Generative AI Guidance v1.3 

Approved Gen AI Systems 

Systems: The City of Long Beach approves the use of MS Copilot Chat, the City’s 
enterprise Gen AI system, for use cases related to enhancing staff productivity. You can 
access it by going to m365copilot.com and logging in with your longbeach.gov account. Visit 
the TI intranet site for more information. The City also approves the use of MS Teams for 
AI-powered meeting transcription.  

Requirements for Use:  

•  You must complete training and sign this acknowledgement form in order to 

activate MS Copilot Chat in your browser.  

•  You must adhere to the General Guidelines, specified below.  

Rationale: MS Copilot Chat adheres to the same data protection standards as other 
enterprise Microsoft services like SharePoint and MS Teams, therefore you can safely 
input City information into it when devising your prompts. This is a significant 
advantage of using MS Copilot Chat over other Gen AI systems under review, such as 
ChatGPT, Google Gemini, or Claude. 

Staff can use AI-powered transcription functionality offered in MS Teams, but we ask that 
you turn off the transcription when discussing sensitive and/or private information. 
This is because transcription functionality offered through MS Teams is subject to Public 
Requests Act (PRA) requests and we want to avoid the risk of inaccurate or misleading 
and sensitive information entering the public record. 

Prohibited AI Systems 

Systems: The following AI systems are forbidden to use: Deepseek, Otter.ai and Read AI, 
as well as other AI meeting assistants such as Atlas, Avoma, ClickUp, Colibri, Compas, 
Dubber, Fathom, Fireflies.ai, Gong, Grain, Laxis, Meet Record, MeetGeek, Read AI, Sembly, 
and Zoom AI. 

Requirements for Use: These systems are forbidden.  

Rationale: These systems are prohibited due to serious concerns of transparency, data 
privacy and security. While we acknowledge that AI meeting tools are increasingly used in 
video conferencing platforms such as Teams and Zoom to automate meeting minutes, we 
ask that staff do not use them. If an external collaborator uses one of these tools in 
meetings with you, kindly request that they turn them off. If you are the host of the 
meeting, you can also eject the AI notetaker from the meeting.  

V 1.3 

2 

 
 
 
 
 
",rationale these systems are prohibited due to serious concerns of transparency data privacy and security while we acknowledge that ai meeting tools are increasingly used in video conferencing platforms such as teams and zoom to automate meeting minutes we ask that staff do not use them if an external collaborator uses one of these tools in meetings with you kindly request that they turn them off if you are the host of the meeting you can also eject the ai notetaker from the meeting
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",sample language to request external collaborators to turn off their ai meeting assistants due to serious concerns of data privacy and security our city policy does not permit the use of ai meeting assistants kindly ask that you please turn them off for this meeting thank you for your understanding
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",department procured gen ai systems
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",requirements for use if your department has entered into contract or is considering negotiating contract with gen ai provider you must work with the tid cybersecurity and data security teams at so we can assist you with resources and guidance
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",gen ai systems under review
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",systems chat gpt google gemini claude and other systems not mentioned in this guidance
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",requirements for use
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",adhere to the general guidelines specified below adhere to the following procedures for protecting sensitive and private information
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",account creation and opting out of data collection
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",rationale we understand that certain sophisticated gen ai use cases cannot be supported by ms copilot chat for those use cases you can continue to access one of the gen ai tools under review
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",sensitive and private information
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",you cannot submit sensitive city information or private information of any individual or entity into chat gpt google gemini claude or any other third party ai tool this includes but is not limited to pii phi pci and hipaa protected information everything you enter into these systems is subject to pra requests may be used to train the underlying models and may be compromised if they experience data breach
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",sensitive and private information includes but is not limited to the following
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",personally identifiable information pii protected health information phi tax ids passport numbers driver license numbers addresses contact details financial information credit card numbers and more
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",passwords passcodes and other confidential information sensitive business data
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",any information that if exposed publicly would tarnish or harm the
LongBeach.pdf,3,"City of Long Beach Generative AI Guidance v1.3 

Sample language to request external collaborators to turn off their AI meeting 
assistants: “Due to serious concerns of data privacy and security, our City policy does not 
permit the use of AI meeting assistants. I kindly ask that you please turn them off for this 
meeting. Thank you for your understanding.” 

Department-procured Gen AI Systems 

Requirements for Use: If your Department has entered into a contract or is considering 
negotiating a contract with a Gen AI provider, you must work with the TID cybersecurity 
and data security teams at smartcity@longbeach.gov, so we can assist you with resources 
and guidance. 

Gen AI Systems Under Review 

Systems: ChatGPT, Google Gemini, Claude and other systems not mentioned in this 
guidance. 

Requirements for Use:  

•  Adhere to the General Guidelines, specified below. 
•  Adhere to the following procedures for protecting sensitive and private information, 

account creation, and opting out of data collection.  

Rationale: We understand that certain sophisticated Gen AI use cases cannot be 
supported by MS Copilot Chat. For those use cases, you can continue to access one of the 
Gen AI tools under review.  

Sensitive and private information: 

You cannot submit sensitive City information or private information of any individual or 
entity into ChatGPT, Google Gemini, Claude, or any other third-party AI tool. This includes, 
but is not limited to PII, PHI, PCI, and HIPAA-protected information. Everything you enter 
into these systems is subject to PRA requests, may be used to train the underlying models, 
and may be compromised if they experience a data breach.  

Sensitive and private information includes but is not limited to the following: 

1.  Personally identifiable information (PII), Protected Health Information (PHI), Tax IDs, 
passport numbers, driver’s license numbers, addresses, contact details, financial 
information, credit card numbers, and more. 

2.  Passwords, passcodes, and other confidential information. 
3.  Sensitive business data:   

a.  Any information that if exposed publicly would tarnish or harm the 

reputation of the City. 

V 1.3 

3 

 
 
 
 
 
 
",reputation of the city
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",any information that if exposed publicly would open the city to regulatory or
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",legal action
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",email address for professional use
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",if you wish to use one of the gen ai providers under review chat gpt google gemini or claude we recommend you create new email address just for professional use separate from your city of long beach email or your existing personal email and use the new email to create an account note that the new account will be subject to pra requests
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",we recommend that you do not use your longbeach gov email address in setting up gen ai system account this is because integration of gen ai systems with the city microsoft environment which includes outlook calendar one drive share point and teams is currently not permitted if you already have gen ai system account with your longbeach gov email you can continue to use it
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",opting out of data collection
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",gen ai retains and shares the data you input and the content it generates as part of its training and self learning processes we encourage you to opt out of data collection when using gen ai system other than ms copilot chat so it does not keep record of your interactions with it some gen ai systems offer this option which is typically found within system privacy settings or user settings
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",below is step by step guide on opting out of chat gpt data collection
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",select your name on the top right of the interface then select settings click data controls in the settings menu and disable improve the model for
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",everyone
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",in addition chat gpt allows users to disable its memory so it does not
LongBeach.pdf,4,"City of Long Beach Generative AI Guidance v1.3 

b.  Any information that if exposed publicly would open the City to regulatory or 

legal action. 

Email address for professional use:  

If you wish to use one of the Gen AI providers under review (ChatGPT, Google Gemini,  or 
Claude), we recommend you create a new email address just for professional use 
(separate from your City of Long Beach email or your existing personal email) and use the 
new email to create an account. Note that the new account will be subject to PRA 
requests. 

We recommend that you do not use your longbeach.gov email address in setting up a Gen 
AI system account. This is because integration of Gen AI systems with the City’s 
Microsoft environment (which includes Outlook, Calendar, OneDrive, SharePoint and 
Teams) is currently not permitted. If you already have a Gen AI system account with your 
longbeach.gov email, you can continue to use it. 

Opting out of data collection: 

Gen AI retains and shares the data you input and the content it generates as part of its 
training and self-learning processes. We encourage you to opt-out of data collection when 
using a Gen AI system other than MS Copilot Chat, so it does not keep a record of your 
interactions with it. Some Gen AI systems offer this option, which is typically found within a 
system’s privacy settings or user settings. 

Below is a step-by-step guide on opting out of ChatGPT’s data collection.  

1.  Select your name on the top right of the interface, then select “Settings” 
2.  Click “Data controls” in the settings menu and disable “Improve the model for 

everyone” 

3.  In addition, Chat GPT allows users to disable its “memory” so it does not 

remember details and preferences between your chats, so what you enter in 

V 1.3 

4 

 
 
 
 
 
",remember details and preferences between your chats so what you enter in
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",one chat will not impact your next one to do this from the settings menu select personalization then disable the two reference saved memories and reference chat history toggles chat gpt conversations will only be retained for days in this mode
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",general guidelines
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",below is list of important practices intended to encourage responsible and innovative use of gen ai while minimizing risks to the city and to the public
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",reviewing gen ai output
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",carefully review verify and fact check via multiple sources the content generated by gen ai to eliminate instances of bias offensive inaccurate or harmful material acknowledge that gen ai systems can reflect cultural social and economic biases of source material you are responsible for verifying that the information is accurate to mitigate biases and misinformation
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",citing use of gen ai
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",you are encouraged to cite or reference within your documents and share with tid via this log form when you use gen ai for particularly impactful and or creative use cases while we realize it is impractical to cite or share every instance of gen ai use we ask that you reference gen ai in instances where it proved particularly impactful to your work or where minimal edits were made to the gen ai output leading up to final version of your work product as is likely the case with generating images our goal is to build positive culture around using gen ai systems enhance peer to peer learning and empower others to boost their productivity
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",citations for content created by gen ai should be in the form of statement within your document or as footnote endnote or header they should include which gen ai system was used and confirmation that you have fact checked everything
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",gen ai system name of the gen ai system dd mm yyyy date when content was generated confirmation that you fact checked the information
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",in text citation example this report summary was drafted with support from gen ai system on dd mm yyyy the content was edited for accuracy and brevity and fact checked by city staff
LongBeach.pdf,5,"City of Long Beach Generative AI Guidance v1.3 

one chat will not impact your next one. To do this, from the Settings menu, 
select “Personalization,” then disable the two “Reference saved memories” and 
“Reference chat history” toggles. Chat GPT conversations will only be retained for 
30 days in this mode. 

General Guidelines 

Below is a list of important practices intended to encourage responsible and innovative use 
of Gen AI while minimizing risks to the City and to the public. 

Reviewing Gen AI output: 

Carefully review, verify, and fact-check via multiple sources the content generated 
by Gen AI to eliminate instances of bias, offensive, inaccurate, or harmful material. 
Acknowledge that Gen AI systems can reflect cultural, social, and economic biases of 
source material. You are responsible for verifying that the information is accurate to 
mitigate biases and misinformation. 

Citing use of Gen AI: 

You are encouraged to cite or reference within your documents and share with TID 
via this Log Form (https://forms.office.com/g/PTAgN6q988) when you use Gen AI for 
particularly impactful and/or creative use cases. While we realize it is impractical to cite 
or share every instance of Gen AI use, we ask that you reference Gen AI in instances where 
it proved particularly impactful to your work OR where minimal edits were made to the 
Gen AI output leading up to a final version of your work product (as is likely the case 
with generating images).  Our goal is to build a positive culture around using Gen AI 
systems, enhance peer-to-peer learning, and empower others to boost their productivity.   

Citations for content created by Gen AI should be in the form of a statement within your 
document or as a footnote, endnote, or header. They should include which Gen AI system 
was used and confirmation that you have fact-checked everything: 

•  GEN AI SYSTEM: Name of the Gen AI system  
•  DD/MM/YYYY: Date when content was generated. 
•  Confirmation that you fact-checked the information. 

In-text citation example: “This report summary was drafted with support from (GEN AI SYSTEM) 
on DD/MM/YYYY. The content was edited for accuracy and brevity and fact-checked by City staff.” 

Footnote/endnote/header example: (GEN AI SYSTEM, DD/MM/YY. Fact checked by City staff and 
edited for accuracy and brevity.) 

V 1.3 

5 

 
 
 
 
 
",footnote endnote header example gen ai system dd mm yy fact checked by city staff and edited for accuracy and brevity
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",department specific guidance
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",city departments may provide additional rules for their staff regarding gen ai if your department bureau or division has additional guidelines for gen ai please inform tid at we can assist you with resources and guidance
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",gen ai staff workgroup
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",we encourage you to participate in the city gen ai staff workgroup we meet virtually once every two months to stay up to date on ai topics provide feedback on the city ai work share out impactful ai use cases and understand departments progress and needs if you are interested in joining please complete this form
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",assessing risk in gen ai use cases
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",the risk presented by gen ai tools varies by use case with the risk spectrum ranging from mid risk to high risk to intolerable risk san jose data privacy office developed the following framework
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",two key factors determine gen ai risk
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",risk of information breach the potential harm if the information exchanged with
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",gen ai is released to an unintended audience this can include entering personally identifiable information sensitive records or confidential business information into gen ai additionally any information entered into gen ai may be subject to pra requests if you wouldn share the information in public forum don share it with gen ai system
LongBeach.pdf,6,"City of Long Beach Generative AI Guidance v1.3 

Department-specific Guidance 

City Departments may provide additional rules for their staff regarding Gen AI. If 
your Department, Bureau, or Division has additional guidelines for Gen AI, please inform 
TID at smartcity@longbeach.gov,so we can assist you with resources and guidance. 

Gen AI Staff Workgroup: 

We encourage you to participate in the City’s Gen AI Staff Workgroup. We meet 
virtually once every two months to stay up to date on AI topics, provide feedback on the 
City’s AI work, share out impactful AI use cases, and understand departments’ progress and 
needs. If you are interested in joining, please complete this form: 
https://forms.office.com/g/PTAgN6q988  

Assessing Risk in Gen AI Use Cases: 

The risk presented by Gen AI tools varies by use case, with the risk spectrum ranging from 
mid-risk to high-risk to intolerable risk. San Jose’s Data Privacy Office developed the 
following framework. 

Two key factors determine Gen AI risk: 

1.  Risk of information breach: the potential harm if the information exchanged with 

a Gen AI is released to an unintended audience. This can include entering personally 
identifiable information, sensitive records, or confidential business information into 
Gen AI. Additionally, any information entered into Gen AI may be subject to PRA 
requests. If you wouldn’t share the information in a public forum, don’t share it with 
a Gen AI system. 

2.  Risk of adverse impact: the potential harm of using the output for a decision, task, 
or service. This impact may manifest itself differently for different populations and 
should be considered from an equity lens, such as adverse impacts on people of a 
certain race, age, gender identity, or disability status. Not only can Gen AI be biased, 
but it can also provide false information. In general, if Gen AI is used in relation to 
City processes that can alter an individual or community’s rights, freedoms, or 
access to services, multiple users should thoroughly review it before any document 
is finalized or action is taken. 

V 1.3 

6 

 
 
 
 
",risk of adverse impact the potential harm of using the output for decision task or service this impact may manifest itself differently for different populations and should be considered from an equity lens such as adverse impacts on people of certain race age gender identity or disability status not only can gen ai be biased but it can also provide false information in general if gen ai is used in relation to city processes that can alter an individual or community rights freedoms or access to services multiple users should thoroughly review it before any document is finalized or action is taken
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",recommended trainings and resources
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",training on learn
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",in the course catalog select artificial intelligence ai from the categories
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",dropdown menu to access the following series of short videos
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",ai chatbots understanding their use risks and limitations in the
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",workplace
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",world wild web using ai tools for work deepfakes scams and disinformation
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",highly recommended
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",innovate us course responsible ai for public professionals
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",ms copilot chat overview
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",ms copilot chat overview video ms copilot chat microsoft copilot chat for all users
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",effective prompts
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",write effective prompts to achieve optimal results
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",ai use cases
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",start your ai journey with microsoft copilot chat work smarter with microsoft copilot chat microsoft scenario library
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",gen ai overview
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",about generative ai harvard university information technology what is generative ai an ai explains world economic forum
LongBeach.pdf,7,"City of Long Beach Generative AI Guidance v1.3 

Recommended Trainings and Resources 

•  Training on LEARN 

a.  In the Course Catalog, select ‘Artificial Intelligence (AI)’ from the ‘Categories’ 

dropdown menu to access the following series of short videos: 

i.  AI Chatbots: Understanding Their Use, Risks, and Limitations in the 

Workplace  

ii.  World Wild Web: Using AI Tools for Work   
iii.  Deepfakes, Scams, and Disinformation 

•  Highly Recommended   

a.  InnovateUS Course: Responsible AI for Public Professionals 

•  MS Copilot Chat Overview 

a.  MS Copilot Chat Overview Video 
b.  MS 365 Copilot Chat  
c.  Microsoft 365 Copilot Chat for all users  

•  Effective Prompts 

a.  Write effective prompts to achieve optimal results  

•  AI Use Cases 

a.  Start your AI journey with Microsoft 365 Copilot Chat 
b.  Work smarter with Microsoft 365 Copilot Chat  
c.  Microsoft Scenario Library 

•  Gen AI Overview 

a.  About Generative AI (Harvard University Information Technology):  
b.  What is Generative AI? An AI Explains (World Economic Forum):  

•  The GovAI Coalition 

V 1.3 

7 

 
 
 
 
 
 
",the gov ai coalition
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",serves as community of practice for government agencies promoting
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",responsible and purposeful ai in the public sector we encourage city staff to join one of the coalition working committees and review their online resources
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",principles
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",these principles describe general codes of conduct that represent the city values and align with our responsibilities to the residents we serve they guide city employees in their use of gen ai technology city employees should adhere to these principles and should champion accountability and compliance among their peers
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",the following principles reflect what we heard from city staff in tid gen ai survey they build upon the city code of conduct and ethics smart city initiative guiding principles and data privacy guidelines
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",safety security
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",every technology we employ impacts the safety and security of our overall
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",environment both physically and digitally we must be mindful of safe data privacy practices for our constituents and minimize security risks presented by generative ai we commit to protecting personal data to the greatest extent possible by ensuring that data that is sensitive proprietary and non public is never used in publicly available gen ai apps
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",we must be aware that generative ai applications and models can be
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",compromised with malicious links and prompts if they are not kept up to date and combined with sound security practices
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",empowerment
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",the use of gen ai should support our work to deliver better safer more
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",efficient and equitable services and products to our residents
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",we trust our staff to do the right thing given the right tools and guidance staff will need to exercise judgement to ensure we get the benefits from generative ai tools while avoiding negative impacts on the city and its constituents
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",exploratory mindset
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",we embrace the possibilities of technology and innovation and commit to responsibly exploring and evaluating creative ai technologies that can advance positive outcomes
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",we acknowledge we are still learning about the full scope of what generative
LongBeach.pdf,8,"City of Long Beach Generative AI Guidance v1.3 

a.  Serves as a community of practice for government agencies promoting 

responsible and purposeful AI in the public sector. We encourage City staff to 
join one of the Coalition’s working committees and review their online 
resources. 

Principles 

These principles describe general codes of conduct that represent the City’s values and 
align with our responsibilities to the residents we serve. They guide City employees in their 
use of Gen AI technology. City employees should adhere to these principles and should 
champion accountability and compliance among their peers. 

The following principles reflect what we heard from City staff in TID’s Gen AI survey. They 
build upon the City’s Code of Conduct and Ethics, Smart City Initiative Guiding Principles, 
and Data Privacy Guidelines. 

Safety & Security 

•  Every technology we employ impacts the safety and security of our overall 

environment, both physically and digitally. We must be mindful of safe data 
privacy practices for our constituents and minimize security risks presented 
by Generative AI. We commit to protecting personal data to the greatest 
extent possible by ensuring that data that is sensitive, proprietary, and non-
public is never used in publicly available Gen AI apps. 

•  We must be aware that Generative AI applications and models can be 

compromised with malicious links and prompts if they are not kept up to 
date and combined with sound security practices. 

Empowerment 

•  The use of Gen AI should support our work to deliver better, safer, more 

efficient, and equitable services and products to our residents. 

•  We trust our staff to do the right thing given the right tools and guidance. 
Staff will need to exercise judgement to ensure we get the benefits from 
Generative AI tools while avoiding negative impacts on the City and its 
constituents. 

Exploratory Mindset 

•  We embrace the possibilities of technology and innovation and commit to 
responsibly exploring and evaluating creative AI technologies that can 
advance positive outcomes.  

•  We acknowledge we are still learning about the full scope of what Generative 

AI can provide us with, so let’s learn together.  

V 1.3 

8 

 
 
 
 
 
 
 
 
 
 
",ai can provide us with so let learn together
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",transparency accountability
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",we acknowledge that we do not have all the answers nor can we foresee all consequences of adopting this technology we recognize further research into this technology may reveal issues that require more restrictions on its use
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",we will be transparent when updates to this guidance are implemented and will hold ourselves accountable to the possible impacts this technology may have
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",the city will practice data integrity and use content produced by gen ai for
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",stated purposes and purposes that serve the public good
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",generative ai is tool we are responsible for the outcomes of our tools for
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",example if autocorrect unintentionally changes word changing the meaning of something we wrote we are still responsible for the text technology enables our work it does not excuse our judgment or accountability
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",equity inclusion
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",we are stewards of the public and we will use generative ai to support and
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",uplift our communities
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",everything we do regardless of the tools is reflection of the city and
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",ourselves we acknowledge that ai systems have the potential to perpetuate inequities discrimination harm and bias against long beach residents and the city will commit to using racial equity lens to examine the burdens benefits and unintended consequences of gen ai
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",we acknowledge that generative ai introduces concerns about job security and job displacement and we recognize that we must be resilient as workforce in the face of emerging technologies
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",definitions
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",generative artificial intelligence commonly referred to as generative ai or gen
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",ai is an automated system used to generate content gen ai uses massive datasets to develop content when given prompt common gen ai systems include chat gpt google gemini claude ms copilot and others
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",traditional ai is an artificial intelligence system trained for specific narrowly defined task commonly used ai systems include google search algorithm recommendation engines like netflix or amazon and writing assistants like grammarly
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",large language models llms are type of ai model trained on immense
LongBeach.pdf,9,"City of Long Beach Generative AI Guidance v1.3 

Transparency & Accountability 

•  We acknowledge that we do not have all the answers, nor can we foresee all 
consequences of adopting this technology. We recognize further research 
into this technology may reveal issues that require more restrictions on its 
use. 

•  We will be transparent when updates to this Guidance are implemented and 
will hold ourselves accountable to the possible impacts this technology may 
have.  

•  The City will practice data integrity and use content produced by Gen AI for 

stated purposes and purposes that serve the public good. 

•  Generative AI is a tool. We are responsible for the outcomes of our tools. For 

example, if autocorrect unintentionally changes a word, changing the 
meaning of something we wrote, we are still responsible for the text. 
Technology enables our work; it does not excuse our judgment or 
accountability. 

Equity & Inclusion  

•  We are stewards of the public and we will use Generative AI to support and 

uplift our communities.  

•  Everything we do, regardless of the tools, is a reflection of the City and 

ourselves. We acknowledge that AI systems have the potential to perpetuate 
inequities, discrimination, harm, and bias against Long Beach residents, and 
the City will commit to using a racial equity lens to examine the burdens, 
benefits, and unintended consequences of Gen AI. 

•  We acknowledge that Generative AI introduces concerns about job security 
and job displacement, and we recognize that we must be resilient as a 
workforce in the face of emerging technologies. 

Definitions 

•  Generative Artificial Intelligence, commonly referred to as “Generative AI” or “Gen 

AI”, is an automated system used to generate “content.” Gen AI uses massive 
datasets to develop content when given a prompt. Common Gen AI systems include 
ChatGPT, Google Gemini, Claude, MS Copilot, and others. 

•  Traditional AI is an artificial intelligence system trained for a specific, narrowly 
defined task. Commonly used AI systems include Google’s search algorithm, 
recommendation engines like Netflix or Amazon, and writing assistants like 
Grammarly.  

•  Large Language Models (LLMs) are a type of AI model trained on immense 

amounts of broad data. They are capable of understanding and generating natural 

V 1.3 

9 

 
 
 
 
 
 
",amounts of broad data they are capable of understanding and generating natural
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",language and other types of content to perform wide range of tasks with minimal fine tuning
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",training data is data gathered from wide range of sources available on the
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",internet such as books websites articles and other texts the gen ai system uses this data to understand user prompts and generate content
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",personally identifiable information or pii for short is any data used to identify
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",someone
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",the california public records act pra gives residents the right to access the public records that the government maintains rights california public records act html
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",change log
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",version notes
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",interim guidance published guidance updated to reflect the evolving ai system landscape reinforce ai systems privacy and security risks and explain the city posture on common ai systems updated glossary to distinguish between gen ai and traditional ai added language about permitted systems added guideline added sections summary of key guidelines getting started gen ai system integration prohibited systems and next steps reordered guidelines added guideline and reframed the requirement to cite ai use as an encouragement to cite reframed the requirement to log instances of gen ai use as an encouragement to log instances of particularly impactful creative gen ai use updated the how to opt out of data collection section with latest features of chat gpt thoroughly restructured document and added an approved gen ai systems section updated trainings and resources and definitions section deleted sample use cases and history sections
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",date jan aug
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",may
LongBeach.pdf,10,"City of Long Beach Generative AI Guidance v1.3 

language and other types of content to perform a wide range of tasks with minimal 
fine-tuning. 

•  Training data is data gathered from a wide range of sources available on the 

internet, such as books, websites, articles, and other texts. The Gen AI system uses 
this data to understand user prompts and generate “content.” 

•  Personally Identifiable Information, or PII for short, is any data used to identify 

someone. 

•  The California Public Records Act (PRA) gives residents the right to access the 
public records that the government maintains. https://www.ftb.ca.gov/your-
rights/california-public-records-act.html 

Change Log 

Version  Notes 
V1.0 
V1.1 

Interim Guidance published 
Guidance updated to reflect the evolving AI system 
landscape, reinforce AI systems’ privacy and security risks, 
and explain the City’s posture on common AI systems. 
Updated glossary to distinguish between Gen AI and 
traditional AI. Added language about permitted systems. 
Added Guideline #9. 
Added sections ‘Summary of Key Guidelines, ‘Getting 
Started,’ ‘Gen AI System Integration,’ ‘Prohibited Systems,’ 
and ‘Next steps.’ Reordered guidelines. Added Guideline #2 
and #5. Reframed the requirement to cite AI use as an 
encouragement to cite. Reframed the requirement to log 
instances of Gen AI use as an encouragement to log 
instances of particularly impactful / creative Gen AI use. 
Updated the ‘How to Opt-Out of Data Collection’ section 
with latest features of ChatGPT. 
Thoroughly restructured document and added an 
‘Approved Gen AI Systems’ section. Updated ‘Trainings and 
Resources’ and ‘Definitions’ section. Deleted ‘Sample Use 
Cases’ and ‘History’ sections.  

Date 
Jan 8, 2024 
Aug 13, 2024 

May 27, 2025 

Nov 17, 2025 

V1.2 

V1.3 

V 1.3 

10 

 
 
 
 
 
 
",nov
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",purpose
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",this policy establishes governance structure that allows the city of san jos hereafter referred to as city to utilize artificial intelligence ai and ai systems systems while providing the necessary safeguards for purposeful and responsible use
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",the key objectives of the ai policy are to
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",provide guidance that is clear easy to follow and supports decision making for the staff interns consultants contractors partners and volunteers who may be purchasing configuring developing using maintaining or leveraging ai to provide services to the city ensure that the use of ai systems adheres to the guiding principles with regard to how
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",systems are purchased configured developed operated or maintained
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",define roles and responsibilities related to the usage of ai establish and maintain processes to assess and manage risks presented by ai align the governance of ai with existing data governance security and privacy measures in accordance with the city information and systems security policy and city council digital privacy policy
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",define prohibited uses of ai systems establish sunset procedures to safely retire systems that no longer meet the needs of the
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",city and
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",define how ai may be used for legitimate purposes in accordance with applicable local state
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",and federal laws and existing agency policies
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",ai systems and the data contained therein will be purchased configured developed operated and maintained using the city ai handbook which will be managed by the chief information officer cio
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",scope
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",this policy applies to
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",all systems deployed by the city and staff interns consultants contractors partners and volunteers who may be purchasing configuring developing using or maintaining the ai or who may be leveraging systems to provide services to the city collectively referred to as users
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",guiding principles for responsible ai systems
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",these principles describe the city values with regard to how ai systems are purchased configured developed used or maintained
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",effectiveness systems are reliable meet their objectives and deliver precise and
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",dependable outcomes for the utility and contexts in which they are deployed
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",transparency the purpose and use of systems is proactively communicated and disclosed to the public system its data sources operational model and policies that govern its use are understandable and documented
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",equity systems deliberately support equitable outcomes for everyone bias in systems is
SanJose.pdf,1,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

PURPOSE 

This policy establishes a governance structure that allows the City of San José (hereafter referred 
to  as  “City”)  to  utilize  Artificial  Intelligence  (AI)  and  AI  systems  (systems)  while  providing  the 
necessary safeguards for purposeful and responsible use. 

The key objectives of the AI Policy are to: 

•  Provide  guidance  that  is  clear,  easy  to  follow,  and  supports  decision-making  for  the  staff, 
interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring, developing, using, maintaining, or leveraging AI to provide services to the City; 
•  Ensure  that  the  use  of  AI  systems  adheres  to  the  Guiding  Principles  with  regard  to  how 

systems are purchased, configured, developed, operated, or maintained; 

•  Define roles and responsibilities related to the usage of AI; 
•  Establish and maintain processes to assess and manage risks presented by AI; 
•  Align the governance of AI with existing data governance, security, and privacy measures in 
accordance with the City’s Information and Systems Security Policy and City Council’s Digital 
Privacy Policy; 

•  Define prohibited uses of AI systems; 
•  Establish “sunset” procedures to safely retire systems that no longer meet the needs of the 

City; and 

•  Define how AI may be used for legitimate purposes in accordance with applicable local, state, 

and federal laws, and existing agency policies. 

AI systems and the data contained therein will be purchased, configured, developed, operated, and 
maintained  using  the  City’s  AI  Handbook,  which will  be  managed  by  the  Chief  Information  Officer 
(CIO). 

SCOPE 

This policy applies to: 

1.  All systems deployed by the City; and 
2.  Staff,  interns,  consultants,  contractors,  partners,  and  volunteers  who  may  be  purchasing, 
configuring,  developing, using,  or  maintaining the  AI  or  who may be  leveraging  systems  to 
provide services to the City (collectively referred to as ""users""). 

GUIDING PRINCIPLES FOR RESPONSIBLE AI SYSTEMS 

These  principles  describe  the  City’s  values  with  regard  to  how  AI  systems  are  purchased, 
configured, developed, used, or maintained.  

1.  Effectiveness:  Systems  are  reliable,  meet  their  objectives,  and  deliver  precise  and 

dependable outcomes for the utility and contexts in which they are deployed; 

2.  Transparency: The purpose and use of systems is proactively communicated and disclosed 
to the public. A system, its data sources, operational model, and policies that govern its use 
are understandable and documented;  

3.  Equity:  Systems  deliberately  support  equitable outcomes  for  everyone.  Bias  in  systems  is 

Effective Date: June 28, 2024 
Page 1 of 4 

 
 
 
 
 
 
 
 
 
 
 
",page of
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",effectively managed with the intention of reducing harm for anyone impacted by the system use
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",accountability roles and responsibilities govern the deployment and maintenance of
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",systems and human oversight ensures adherence to relevant laws and regulations
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",human centered design systems are developed and deployed with human centered
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",approach that evaluates ai powered services for their impact on the public
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",privacy privacy is preserved in all ai systems by safeguarding personally identifiable information pii and sensitive data from unauthorized access disclosure and manipulation in accordance with the city council digital privacy policy
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",security safety systems maintain confidentiality integrity and availability through safeguards in accordance with the city information and systems security policy the integrity of information into and out of the city is maintained in light of fake ai generated content implementation of systems is reliable and safe minimizing risks to individuals society and the environment and
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",workforce empowerment staff are empowered to use ai in their roles through education
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",training and collaborations that promote participation and opportunity
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",responsibilities
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",several roles are responsible for enforcing this policy outlined below
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",the information technology department director chief information officer cio is responsible for directing technology resources policies projects services and coordinating the same with other departments the cio shall designate the city information security officer ciso and city digital privacy officer cdpo to actively ensure the security resilience privacy and policy compliance of the systems used by the city
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",the ciso and cdpo are responsible for recommending updates to this policy and the ai
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",handbook
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",policy
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",when purchasing configuring developing using or maintaining ai systems users will
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",uphold the guiding principles for ai systems outlined above conduct an ai review to assess the potential risk of the ai system the cdpo or designee is responsible for coordinating review of ai systems used by the city as detailed in the ai handbook
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",obtain technical documentation about ai systems the finance department or other department overseeing the purchase of an ai system is responsible for requiring vendors to disclose ai usage and to provide technical documentation via the ai fact sheet as defined in the terms and definitions section below at the request of the cdpo and
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",in the event of an incident involving the use of the ai system follow the city ai incident response plan in accordance with the information and systems security policy the ciso is responsible for overseeing the security practices of ai systems used by or on behalf the city
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",additionally finance is required to ask vendors to disclose the use of ai in procurement solicitations and to comply with the requirements for ai systems upon the request of the cdpo or designee
SanJose.pdf,2,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

effectively managed with the intention of reducing harm for anyone impacted by the system’s 
use;  

4.  Accountability:  Roles  and  responsibilities  govern  the  deployment  and  maintenance  of 

systems, and human oversight ensures adherence to relevant laws and regulations;  

5.  Human-Centered  Design:  Systems  are  developed  and  deployed  with  a  human-centered 

approach that evaluates AI powered services for their impact on the public; 

6.  Privacy:  Privacy  is  preserved  in  all  AI  systems  by  safeguarding  personally  identifiable 
information (PII) and sensitive data from unauthorized access, disclosure, and manipulation 
in accordance with the City Council’s Digital Privacy Policy; 

7.  Security  &  Safety:  Systems  maintain  confidentiality,  integrity,  and  availability  through 
safeguards  in  accordance  with  the  City’s  Information  and  Systems  Security  Policy.  The 
integrity  of  information  into  and  out  of  the  City  is  maintained  in  light  of  fake  AI-generated 
content.  Implementation  of  systems  is  reliable  and  safe,  minimizing  risks  to  individuals, 
society, and the environment; and 

8.  Workforce Empowerment: Staff are empowered to use AI in their roles through education, 

training, and collaborations that promote participation and opportunity. 

RESPONSIBILITIES 

Several roles are responsible for enforcing this Policy, outlined below. 

•  The  Information  Technology  Department  Director  /  Chief  Information  Officer  (CIO)  is 
responsible for directing technology resources, policies, projects, services, and coordinating 
the same with other departments. The CIO shall designate the City Information Security Officer 
(CISO)  and  City  Digital  Privacy  Officer  (CDPO)  to  actively  ensure  the  security,  resilience, 
privacy, and policy compliance of the systems used by the City.  

•  The  CISO  and  CDPO  are  responsible  for  recommending  updates  to  this  policy  and  the  AI 

Handbook. 

POLICY 

When purchasing, configuring, developing, using, or maintaining AI systems, users will:  

1.  Uphold the Guiding Principles for AI systems outlined above; 
2.  Conduct an AI Review to assess the potential risk of the AI system. The CDPO or designee is 
responsible  for  coordinating  review  of  AI  systems  used  by  the  City  as  detailed  in  the  AI 
Handbook; 

3.  Obtain  technical  documentation  about  AI  systems.  The  Finance  Department,  or  other 
department overseeing the purchase of an AI system, is responsible for requiring vendors to 
disclose  AI  usage  and  to  provide  technical  documentation  (e.g.,  via  the  AI  FactSheet  as 
defined in the Terms and Definitions section, below) at the request of the CDPO; and 

4.  In  the  event  of  an  incident  involving  the  use  of  the  AI  system,  follow  the  City’s  AI  Incident 
Response Plan in accordance with the Information and Systems Security Policy. The CISO is 
responsible for overseeing the security practices of AI systems used by or on behalf the City. 

Additionally, Finance is required to ask vendors to disclose the use of AI in procurement solicitations 
and to comply with the Requirements for AI Systems upon the request of the CDPO or designee. 

Effective Date: June 28, 2024 
Page 2 of 4 

 
 
 
 
 
 
 
 
 
 
",page of
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",prohibited uses
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",the use of certain ai systems is prohibited due to the sensitive nature of the information processed and severe potential risk this includes but is not limited to the following prohibited purposes
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",real time and covert biometric identification emotion analysis or the use of computer vision techniques to classify human facial and body movements into certain emotions or sentiment positive negative neutral happy angry nervous
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",fully automated decisions that substantially impact the rights or safety of individuals with no
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",meaningful human oversight
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",social scoring or the use of ai systems to track and classify individuals based on their
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",behaviors socioeconomic status or personal characteristics and
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",cognitive behavioral manipulation of people or specific vulnerable groups
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",if staff become aware of an instance where an ai has caused harm staff must report the instance to their supervisor the cdpo and the office of employee relations no later than hours after discovery
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",sunset procedures
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",if an ai system operated by the city or on its behalf ceases to provide positive outcome to the city as determined by the staff or cdpo then the city must halt the use of that system unless express exception is provided by the cio if the abrupt cessation of the use of that ai system would significantly disrupt the delivery of services gradual phased out approach must be the cio before sunsetting all measures to minimize the impact and recovery must be considered in the termination or phase out protocol including but not limited to
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",ownership and future access of data portability of the ai model algorithm and or data and
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",impact to services users and residents
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",public records
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",the city must consider applicable public records laws before implementing an ai system and must comply with the city open government and ethics provisions and the california public records act more information can be found in city administration policy manual open government policy
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",policy enforcement
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",all employees and agents of the city whether permanent or temporary interns volunteers contractors consultants vendors and other third parties operating ai systems on behalf of the city are required to abide by this policy and the associated ai handbook
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",violations of the ai policy
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",violations of any section of the ai policy including failure to comply with the ai handbook may be
SanJose.pdf,3,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

Prohibited Uses 

The use of certain AI systems is prohibited due to the sensitive nature of the information processed 
and severe potential risk.  This includes, but is not limited to, the following prohibited purposes: 

•  Real-time and covert biometric identification; 
•  Emotion analysis, or the use of computer vision techniques to classify human facial and body 
movements into certain emotions or sentiment (e.g., positive, negative, neutral, happy, angry, 
nervous); 

•  Fully automated decisions that substantially impact the rights or safety of individuals with no 

meaningful human oversight; 

•  Social  scoring,  or  the  use  of  AI  systems  to  track  and  classify  individuals  based  on  their 

behaviors, socioeconomic status, or personal characteristics; and 

•  Cognitive behavioral manipulation of people or specific vulnerable groups. 

If staff become aware of an instance where an AI has caused harm, staff must report the instance to 
their  supervisor,  the  CDPO,  and  the  Office  of  Employee  Relations  no  later  than  24  hours  after 
discovery. 

Sunset Procedures 

If an AI system operated by the City or on its behalf ceases to provide a positive outcome to the 
City  as  determined  by  the  staff  or  CDPO,  then the  City must  halt  the  use  of that  system  unless 
express exception is provided by the CIO. If the abrupt cessation of the use of that AI system would 
significantly disrupt the delivery of services, a gradual phased out approach must be approved by 
the CIO before sunsetting. All measures to minimize the impact and recovery must be considered 
in the termination or phase out protocol, including but not limited to: 

•  Ownership and future access of data; 
•  Portability of the AI model, algorithm, and/or data; and 
• 

Impact to services, users, and residents. 

Public Records 

The City must consider applicable public records laws before implementing an AI system and must 
comply  with the  City’s Open Government  and  Ethics  Provisions  and  the California  Public  Records 
Act. More information can be found in City’s Administration Policy Manual 6.1.4 Open Government 
Policy. 

Policy Enforcement 

All  employees  and  agents  of  the  City,  whether  permanent  or  temporary,  interns,  volunteers, 
contractors, consultants, vendors, and other third parties operating AI systems on behalf of the City 
are required to abide by this Policy and the associated AI Handbook. 

VIOLATIONS OF THE AI POLICY 

Violations of any section of the AI Policy, including failure to comply with the AI Handbook, may be 

Effective Date: June 28, 2024 
Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
",page of
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",subject to disciplinary action up to and including termination violations made by third party while operating an ai system on behalf of the city may result in breach of contract and or pursuit of damages infractions that violate local state federal or international law may be remanded to the proper authorities
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",terms and definitions
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",artificial intelligence artificial intelligence or ai is machine based system that can for given set of human defined objectives make predictions recommendations or decisions influencing real or virtual environments artificial intelligence systems use machine and human based inputs to perceive real and virtual environments abstract such perceptions into models through analysis in an automated manner and use model inference to formulate options for information or action
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",algorithm series of logical steps through which an agent typically computer or software program turns particular inputs into particular outputs
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",system any software sensor or process that uses ai to automatically generate outputs including but not limited to predictions recommendations or decisions that augment or replace human decision making this extends to software hardware algorithms and data generated by these systems used to automate large scale processes or analyze large data sets
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",ai fact sheet template that captures the nutrition facts or essential technical details of an ai system vendors are expected to complete the ai fact sheet during the procurement process the ai fact sheet is critical document that provides technical information needed to adequately understand evaluate and use ai systems maintained by the information technology department
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",approved
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",khaled tawfik information technology department director chief information officer
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",approved for posting
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",jennifer maguire city manager
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",date
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",date
SanJose.pdf,4,"City of San José 
Artificial Intelligence (AI) Policy    

                                City Administrative Policy Manual 
                    1.7.12  

subject to disciplinary action, up to and including termination. Violations made by a third party while 
operating an AI system on behalf of the City may result in a breach of contract and/or pursuit of 
damages. Infractions that violate local, state, federal or international law may be remanded to the 
proper authorities. 

TERMS AND DEFINITIONS 

Artificial Intelligence: “Artificial intelligence” or “AI” is a machine-based system that can, for a given 
set of human-defined objectives, make predictions, recommendations, or decisions influencing real 
or  virtual  environments.  Artificial  intelligence  systems  use  machine  and  human-based  inputs  to 
perceive real and virtual environments; abstract such perceptions into models through analysis in an 
automated manner; and use model inference to formulate options for information or action. 

Algorithm:  A  series  of  logical  steps  through  which  an  agent  (typically  a  computer  or  software 
program) turns particular inputs into particular outputs.   

System: Any software, sensor, or process that uses AI to automatically generate outputs including, 
but  not  limited  to,  predictions,  recommendations,  or  decisions  that  augment  or  replace  human 
decision-making.  This  extends  to  software,  hardware,  algorithms,  and  data  generated  by  these 
systems used to automate large-scale processes or analyze large data sets.  

AI Fact Sheet: A template that captures the “nutrition facts,” or essential technical details, of an AI 
system. Vendors are expected to complete the AI Fact Sheet during the procurement process. The 
AI  Fact  Sheet  is  a  critical  document  that  provides  technical  information  needed  to  adequately 
understand, evaluate, and use AI systems.  Maintained by the Information Technology Department. 

Approved: 

/s/ 
Khaled Tawfik 
Information Technology Department 
Director / Chief Information Officer 

Approved for posting: 

/s/ 
Jennifer A. Maguire 
City Manager 

6/28/2024 
Date 

6/28/2024 
Date 

Effective Date: June 28, 2024 
Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",page of
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",for all city and county personnel including employees contractors consultants volunteers and vendors working on behalf of the city
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",july th
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",top guidelines for using generative ai
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",whether generated by ai or human you are ultimately responsible for any content you use or
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",share
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",copilot chat is available to city employees as secure option for most generative ai tasks
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",other secure enterprise tools may also be available to staff we strongly discourage the use of generative ai tools that have not been purchased or vetted by the city if you must use public or consumer generative ai tools never enter sensitive confidential or city data as these tools may store or reuse the information you provide
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",always review edit fact check validate and or test ai generated content which isn always
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",accurate
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",always disclose ai use when it contributes to public facing or sensitive work or required by
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",regulations ensure the generative ai tool is properly recorded in the city inventory and provide direct notice to impacted individuals
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",never use generative ai to generate deepfakes fake images or recordings or other content
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",that could be mistakenly interpreted by someone to be real
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",introduction
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",enterprise generative ai gen ai tools procured and licensed by the department of technology dt are now available for use by staff of the city and county of san francisco city opening new opportunities to improve the effectiveness efficiency and responsiveness of city services for all san franciscans
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",unlike other ai technologies used by the city which support informed decisions based on input data gen ai tools can generate new content based on patterns identified in large datasets often in matter of seconds examples include text images music and code
SF.pdf,1,"San Francisco Generative AI Guidelines (2025) 

For All City and County personnel, including employees, contractors, consultants, volunteers, and vendors 
working on behalf of the City  

July 7th, 2025 

Top 5 Guidelines for Using Generative AI 

1.  Whether generated by AI or a human, you are ultimately responsible for any content you use or 

share. 

2.  Copilot Chat is available to City employees as a secure option for most Generative AI tasks. 

Other secure enterprise tools may also be available to staff. We strongly discourage the use of  
Generative AI tools that have not been purchased or vetted by the City. If you must use  public 
or consumer Generative AI tools, never enter sensitive, confidential, or City data, as these tools 
may store or reuse the information you provide.  

3.  Always review, edit, fact-check, validate, and/or test AI generated content, which isn’t always 

accurate. 

4.  Always disclose AI use when it contributes to public-facing or sensitive work or required by 

regulations. Ensure the Generative AI tool is properly recorded in the City’s 22J inventory and 
provide direct notice to impacted individuals. 

5.  Never use Generative AI to generate deepfakes—fake images or recordings--or other content 

that could be mistakenly interpreted by someone to be real.  

1. Introduction 

Enterprise Generative AI (GenAI) tools procured and licensed by the Department of Technology (DT) are 
now available for use by staff of the City and County of San Francisco (City), opening new opportunities 
to improve the effectiveness, efficiency, and responsiveness of City services for all San Franciscans. 

Unlike other AI technologies used by the City—which support informed decisions based on input data— 
GenAI tools can generate new content based on patterns identified in large datasets, often in a matter 
of seconds. Examples include text, images, music, and code. 

However, the use of GenAI technology by the City also poses unique risks to its workers, residents, and 
visitors.  While AI-generated content can appear authoritative and polished, it can be inaccurate, biased, 
or misleading. GenAI use can also heighten the risk of privacy breaches, unauthorized data sharing, and 
cybersecurity threats. Furthermore, overreliance on GenAI for decisions that affect the public’s rights or 
safety can reduce transparency, weaken accountability, and erode trust in government.  

1 

 
 
 
 
 
 
 
",however the use of gen ai technology by the city also poses unique risks to its workers residents and visitors while ai generated content can appear authoritative and polished it can be inaccurate biased or misleading gen ai use can also heighten the risk of privacy breaches unauthorized data sharing and cybersecurity threats furthermore overreliance on gen ai for decisions that affect the public rights or safety can reduce transparency weaken accountability and erode trust in government
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",purpose of the guidelines
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",these guidelines are designed to help city staff use gen ai tools effectively and responsibly while maintaining public trust protecting resident data and preserving the integrity of city systems
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",although gen ai tools provided by dt offer stronger privacy and security protections compared to public or consumer ai tools they still pose significant risks these include bias misinformation factual errors hallucinations copyright violations and inconsistent outputs such risks are heightened when city employees rely on these tools without exercising the necessary human oversight to mitigate these risks all gen ai outputs should be carefully reviewed before use to ensure accuracy fairness and alignment with city values and policies city staff must also adhere to existing data protection and governance requirements and provide transparency to the public about when and how gen ai tools are being used in compliance with the city ai transparency ordinance chapter
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",scope of the guidelines
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",with some important distinctions the guidelines outlined in sections through of this document apply to both
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",enterprise gen ai tools like chat gpt enterprise microsoft copilot snowflake cortex adobe
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",apps and express and other approved systems licensed and managed through the department of technology dt these tools
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",have been procured and configured for city use allow use of sensitive city data and restrict any vendor use of city data for ai
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",training this includes protected health information phi and personally identifiable information pii when using tools that have business associate agreements baas in place such as microsoft copilot and snowflake cortex
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",have passed cybersecurity risk assessments and support the city data retention standards and obligations for public request for access
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",public or consumer gen ai tools such as free online chatbots or apps not procured or
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",managed by the city these tools do not provide adequate privacy protections and information shared with them is often used to train the underlying models posing potential confidentiality risks
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",while the use of public or consumer gen ai tools for city business is strongly discouraged we recognize that such tools may still be used in limited circumstances if you want to use public or consumer gen ai tools you must obtain prior departmental approval and follow the precautions outlined in section
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",city guidelines for generative ai use
SF.pdf,2,"1.1. Purpose of the Guidelines 

These guidelines are designed to help City staff use GenAI tools effectively and responsibly, while 
maintaining public trust, protecting resident data, and preserving the integrity of City systems. 

Although GenAI tools provided by DT offer stronger privacy and security protections compared to public 
or consumer AI tools, they still pose significant risks. These include bias, misinformation, factual errors, 
hallucinations, copyright violations, and inconsistent outputs. Such risks are heightened when City 
employees rely on these tools without exercising the necessary human oversight. To mitigate these 
risks, all GenAI outputs should be carefully reviewed before use to ensure accuracy, fairness, and 
alignment with City values and policies. City staff must also adhere to existing data protection and 
governance requirements, and provide transparency to the public about when and how GenAI tools are 
being used, in compliance with the City AI Transparency Ordinance (Chapter 22J). 

1.2. Scope of the Guidelines 

With some important distinctions, the guidelines outlined in Sections 2.1 through 2.3 of this document 
apply to both: 

•  Enterprise GenAI tools—like ChatGPT Enterprise, Microsoft Copilot, Snowflake Cortex, Adobe 

apps and Express, and other approved systems—licensed and managed through the Department 
of Technology (DT). These tools:  

o  Have been procured and configured for City use; 
o  Allow use of sensitive City data (and restrict any vendor use of City data for AI 

training). This includes protected health information (PHI) and personally identifiable 
information (PII) when using tools that have Business Associate Agreements (BAAs) in 
place, such as Microsoft Copilot and Snowflake Cortex; 

o  Have passed cybersecurity risk assessments; and 
o  Support the City’s data retention standards and obligations for public request for access 

•  Public or consumer GenAI tools — such as free online chatbots or apps not procured or 

managed by the City. These tools do not provide adequate privacy protections, and information 
shared with them is often used to train the underlying models, posing potential confidentiality 
risks. 

While the use of public or consumer GenAI tools for City business is strongly discouraged, we recognize 
that such tools may still be used in limited circumstances. If you want to use public or consumer GenAI 
tools, you must obtain prior departmental approval and follow the precautions outlined in Section 
2.4. 

2. City Guidelines for Generative AI Use 

The GenAI uses outlined below are grouped by risk level, each with corresponding mitigation strategies 
and disclosure requirements.  

2 

 
 
 
 
 
 
 
 
",the gen ai uses outlined below are grouped by risk level each with corresponding mitigation strategies and disclosure requirements
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",as general rule city employees must always thoroughly review edit fact check validate and or test their output as applicable you are ultimately responsible for any content you use or share
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",low risk use internal efficiency tasks performed using enterprise generative ai tools
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",you may use city procured ai tools for
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",drafting internal emails memos or communications creating summaries of meetings documents or reports writing editing or debugging code generating outlines or first drafts of internal materials
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",improving language access between the general public and city staff
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",these uses help improve efficiency and reduce workload but you remain the expert reviewer
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",safeguards and responsibilities
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",even when handling simple tasks ai can make errors omit context or return outdated or biased information there no such thing as zero risk to ensure responsible and safe use of ai tools
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",for summaries or memos only use material you are already familiar with so you can spot issues
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",you should be able to independently evaluate the quality and correctness of the output always double check factual claims hyperlinks and references to ensure content is backed by
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",evidence
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",always review and edit ai output critically before using or sharing it only use gen ai for coding tasks if you already know the programming language you must be
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",able to review debug and test any ai generated code
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",disclosure requirements
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",disclosure is not required when using ai for internal drafting or support you remain fully responsible for any content you use or share including any errors or omissions introduced by ai
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",medium to high risk use public facing or sensitive work performed using enterprise generative ai tools
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",use extra caution and follow additional steps when city approved ai tools are used to perform tasks affecting public communication services or decisions such as
SF.pdf,3,"As a general rule, City employees must always thoroughly review, edit, fact-check, validate, and/or test 
their output, as applicable. You are ultimately responsible for any content you use or share. 

2.1. Low-Risk Use: Internal Efficiency Tasks Performed Using Enterprise 
Generative AI Tools 

You may use City-procured AI tools for: 

•  Drafting internal emails, memos, or communications 
•  Creating summaries of meetings, documents, or reports 
•  Writing, editing, or debugging code 
•  Generating outlines or first drafts of internal materials 
• 

Improving language access between the general public and City staff. 

These uses help improve efficiency and reduce workload, but you remain the expert reviewer. 

Safeguards and Responsibilities  

Even when handling simple tasks, AI can make errors, omit context, or return outdated or biased 
information. There’s no such thing as zero risk. To ensure responsible and safe use of AI tools:  

•  For summaries or memos, only use material you are already familiar with so you can spot issues. 

You should be able to independently evaluate the quality and correctness of the output. 
•  Always double-check factual claims, hyperlinks, and references to ensure content is backed by 

evidence. 

•  Always review and edit AI’s output critically before using or sharing it. 
•  Only use GenAI for coding tasks if you already know the programming language. You must be 

able to review, debug, and test any AI-generated code. 

Disclosure Requirements 

Disclosure is not required when using AI for internal drafting or support. You remain fully responsible for 
any content you use or share, including any errors or omissions introduced by AI. 

2.2. Medium- to High-Risk Use: Public-Facing or Sensitive Work Performed Using 
Enterprise Generative AI Tools 

Use extra caution and follow additional steps when City-approved AI tools are used to perform tasks 
affecting public communication, services, or decisions such as: 

•  Drafting or translating public-facing content. 
•  Drafting interview questions and screening materials for hiring processes. 
•  Summarizing policy-related data. 
•  Supporting decisions related to services, enforcement, or eligibility. 
•  Contributing to documents that affect regulation or safety. 

3 

 
 
 
 
 
 
 
",drafting or translating public facing content drafting interview questions and screening materials for hiring processes summarizing policy related data supporting decisions related to services enforcement or eligibility contributing to documents that affect regulation or safety
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",for these use cases ai can serve as support tool but it should never make final decisions that affect individuals or public outcomes
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",safeguards and responsibilities
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",to ensure responsible and safe use of enterprise ai tools used to perform public facing or sensitive work
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",only use gen ai if you have deep subject matter expertise to review its output this ensures you can spot errors detect harmful implications review suggestions critically and make informed decisions based in ai generated content
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",review and edit ai generated outputs to ensure they reflect the city values promote equity and uphold ethical standards and digital accessibility standards including the use of inclusive language and design practices that serve residents with visual cognitive or motor impairments
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",actively monitor for instances of bias and correct them manually
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",disclosure requirements
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",when using enterprise gen ai tools for public facing or sensitive work usage should be properly documented through the process
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",to promote transparency toward the public individuals impacted by ai systems must receive direct notice disclosing that gen ai substantially contributed to the work product at minimum this direct notice must include clear plain language multilingual statement that gen ai was used the name and version of the tool used note indicating that the content was reviewed by city staff and contact information for questions appeals or corrections
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",direct notice sample template please check with your department for specific requirements or approved language
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",this content was generated with the assistance of tool name version and reviewed by city staff for accuracy for questions appeals or corrections contact email
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",view this notice in espa ol tagalog or contact email for additional options
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",depending on the type of content and its intended audience other regulatory requirements related to disclosures or disclaimers such as those under ab may also apply staff should always consult with their department for specific guidance on compliance with applicable laws and policies
SF.pdf,4,"For these use-cases, AI can serve as a support tool, but it should never make final decisions that affect 
individuals or public outcomes.  

Safeguards and Responsibilities 

To ensure responsible and safe use of Enterprise AI tools used to perform public-facing or sensitive 
work: 

•  Only use GenAI if you have deep subject-matter expertise to review its output. This ensures you 
can spot errors, detect harmful implications, review suggestions critically, and make informed 
decisions based in AI-generated content. 

•  Review and edit AI-generated outputs to ensure they reflect the City’s values, promote equity, 
and uphold ethical standards and digital accessibility standards including the use of inclusive 
language and design practices that serve residents with visual, cognitive, or motor impairments. 

•  Actively monitor for instances of bias and correct them manually. 

Disclosure Requirements 

When using Enterprise GenAI tools for public-facing or sensitive work, usage should be properly 
documented through the 22J process. 

To promote transparency toward the public, individuals impacted by AI systems must receive a direct 
notice disclosing that GenAI substantially contributed to the work product. At minimum, this direct 
notice must include: a clear plain-language, multilingual statement that GenAI was used; the name and 
version of the tool used; a note indicating that the content was reviewed by City staff; and contact 
information for questions, appeals, or corrections.  

Direct Notice – Sample Template (please check with your department for specific requirements 
or approved language) 

This content was generated with the assistance of [Tool Name, Version] and reviewed by City 
staff for accuracy. 
For questions, appeals, or corrections, contact: [Email]. 

View this notice in: [Español] · [中文] · [Tagalog] 
Or contact [email] for additional options. 

Depending on the type of content and its intended audience, other regulatory requirements related to 
disclosures or disclaimers, such as those under AB 3030, may also apply. Staff should always consult with 
their department for specific guidance on compliance with applicable laws and policies. 

Furthermore,  if you paraphrase, quote, or incorporate any AI-generated content into your own work 
(whether text, image, data, or other), you should cite it appropriately, just as you would any external 
source. Established citation guidelines, such as those from the MLA Style Center, recommend including 
the following details:  a description of the prompt; the name and version of the AI tool; the 
developer/company; the date of interaction; and a URL to the tool or session, if applicable. 

4 

 
 
 
 
 
 
 
 
 
",furthermore if you paraphrase quote or incorporate any ai generated content into your own work whether text image data or other you should cite it appropriately just as you would any external source established citation guidelines such as those from the mla style center recommend including the following details description of the prompt the name and version of the ai tool the developer company the date of interaction and url to the tool or session if applicable
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",example quoting ai generated text
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",when asked to describe the symbolism of the green light in the great gatsby chat gpt provided summary about optimism the unattainability of the american dream greed and covetousness however when further prompted to cite the source on which that summary was based it noted that it lacked the ability to conduct research or cite sources independently but that it could provide list of scholarly sources related to the symbolism of the green light in the great gatsby in words
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",works cited list entry mla style
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",in words describe the symbolism of the green light in the great gatsby follow up prompt to list sources chat gpt feb version open ai mar
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",if gen ai tool references or summarizes secondary sources articles studies or reports you must verify the original material and cite the primary source directly just as you would in traditional research
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",prohibited uses
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",to protect public trust safety and ethical standards do not use gen ai tools for any of the following
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",relying on ai to create city official documents or make decisions without expert human review generating images audio or video that could be mistaken for real people including public
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",officials or members of the public
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",creating deepfakes or impersonations of any person or official even with disclaimers fabricating fictional survey respondents or public input for research or outreach purposes relying on ai to review legal or regulatory issues
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",using public or consumer generative ai tools additional guidance
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",the use of public or consumer generative ai tools in place of city approved enterprise solutions is strongly discouraged any experimental use of non approved generative ai technologies must receive prior departmental approval
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",to ensure the security of city systems and data and best serve the public when using public or consumer gen ai tools follow this guidance in addition to the ones outlined for enterprise gen ai tools
SF.pdf,5,"Example: Quoting AI-Generated Text 

When asked to describe the symbolism of the green light in The Great Gatsby, ChatGPT provided 
a summary about optimism, the unattainability of the American dream, greed, and 
covetousness. However, when further prompted to cite the source on which that summary was 
based, it noted that it lacked “the ability to conduct research or cite sources independently” but 
that it could “provide a list of scholarly sources related to the symbolism of the green light in The 
Great Gatsby” (“In 200 words”). 

Works-Cited-List Entry (MLA Style):  

“In 200 words, describe the symbolism of the green light in The Great Gatsby” follow-up prompt 
to list sources. ChatGPT, 13 Feb. version, OpenAI, 9 Mar. 2023, https://chat.openai.com/chat. 

If a GenAI tool references or summarizes secondary sources (e.g., articles, studies, or reports), you must 
verify the original material and cite the primary source directly, just as you would in traditional research. 

2.3. Prohibited Uses  

To protect public trust, safety, and ethical standards, do not use GenAI tools for any of the following: 

•  Relying on AI to create City official documents or make decisions without expert human review. 
•  Generating images, audio, or video that could be mistaken for real people (including public 

officials or members of the public). 

•  Creating “deepfakes” or impersonations of any person or official—even with disclaimers. 
•  Fabricating fictional survey respondents or public input for research or outreach purposes. 
•  Relying on AI to review legal or regulatory issues. 

2.4. Using Public or Consumer Generative AI Tools: Additional Guidance 

The use of public or consumer Generative AI tools in place of City-approved enterprise solutions is 
strongly discouraged. Any experimental use of non-approved Generative AI technologies must receive 
prior departmental approval.  

To ensure the security of City systems and data and best serve the public when using public or consumer 
GenAI tools, follow this guidance in addition to the ones outlined for Enterprise GenAI Tools:  

•  Never enter sensitive or protected data that cannot be fully released to the public, including 
personal information, health information, City data, and/or financial information. This 
information can be viewed by the companies that make the tools and, in some cases, other 
members of the public. Once entered, this information becomes part of the public record. The 
handling and disclosure of sensitive information is already governed by several City policies, 
including but not limited to: 

5 

 
 
 
 
 
 
 
 
",never enter sensitive or protected data that cannot be fully released to the public including personal information health information city data and or financial information this information can be viewed by the companies that make the tools and in some cases other members of the public once entered this information becomes part of the public record the handling and disclosure of sensitive information is already governed by several city policies including but not limited to
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",charter section privacy first policy administrative code section nondisclosure of private information campaign governmental conduct code section disclosure or use of
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",confidential city information
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",the computers and data information systems section of the department of human
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",resource employee handbook january page
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",please refer to citywide data classification standard for more specifics on data
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",classification and department responsible roles
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",never conceal the use of public or consumer gen ai tools from your coworkers and remain
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",transparent about when and how these tools are used in your work
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",guidance for departmental it leaders
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",departmental it leaders have responsibility to support right sized gen ai uses that deliver the greatest public benefit this begins with ensuring that ai projects are problem led and not technology led by centering the specific needs and challenges faced by the department and the communities it services
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",in parallel departmental it leaders must ensure responsibility and transparency in how gen ai tools are used especially when they could influence department decisions erode the public rights or safety or affect access to critical services this responsibility includes ensuring that their department complies with the transparency requirements set forth in chapter of the administrative code
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",to support these goals it leaders should adhere to the following guidance
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",if your department is considering adopting or piloting new gen ai tool please reach out to the emerging technology team at early in the process to ensure alignment with citywide standards policy requirements and support
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",when purchasing technology that includes gen ai collect the information required by from
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",vendors during contract execution or shortly thereafter this includes the name of the technology and vendor description of its purpose function intended use and operational context training and generated data an explanation of how the technology works what it is optimizing for and its accuracy preferably with numerical metrics conditions affecting performance testing for bias including results procedures for reporting issues or incidents oversight mechanisms and whether collected data may be used to train proprietary or third party systems
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",designate at least one lead responsible for managing compliance with coordinating inventory submissions and acting as the point of contact for the emerging
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",technology team
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",determining whether each gen ai technology your department uses or is planning to
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",procure borrow or receive qualifies for an exemption under
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",submitting required information for non exempt gen ai tools under through
SF.pdf,6,"o  Charter Section 16.130, Privacy First Policy 
o  Administrative Code Section 12M.2(a), Nondisclosure of Private Information 
o  Campaign & Governmental Conduct Code section 3.228, Disclosure or Use of 

Confidential City Information 

o  The “Computers and Data Information Systems” section of the Department of Human 

Resource’s Employee Handbook (January 2012, page 48) 

o  Please refer to Citywide Data Classification Standard for more specifics on data 

classification and department responsible roles 

•  Never conceal the use of public or consumer GenAI tools from your coworkers and remain 

transparent about when and how these tools are used in your work. 

2.5. Guidance for Departmental IT Leaders 

Departmental IT leaders have a responsibility to support right-sized GenAI uses that deliver the greatest 
public benefit. This begins with ensuring that AI projects are problem-led and not technology-led, by 
centering the specific needs and challenges faced by the department and the communities it services. 

In parallel, Departmental IT leaders must ensure responsibility and transparency in how GenAI tools are 
used, especially when they could influence department decisions, erode the public’s rights or safety, or 
affect access to critical services. This responsibility includes ensuring that their department complies 
with the transparency requirements set forth in Chapter 22J of the Administrative Code.  

To support these goals, IT leaders should adhere to the following guidance:  

• 

If your department is considering adopting or piloting a new GenAI tool, please reach out to the 
Emerging Technology Team at ai@sfgov.org early in the process to ensure alignment with 
citywide standards, policy requirements, and support. 

•  When purchasing technology that includes GenAI, collect the information required by 22J from 

vendors during contract execution or shortly thereafter. This includes the name of the 
technology and vendor; a description of its purpose, function, intended use, and operational 
context; training and generated data; an explanation of how the technology works; what it is 
optimizing for and its accuracy (preferably with numerical metrics); conditions affecting 
performance; testing for bias (including results); procedures for reporting issues or incidents; 
oversight mechanisms; and whether collected data may be used to train proprietary or third-
party systems. 

•  Designate at least one 22J Lead responsible for: 
o  Managing compliance with 22J. 
o  Coordinating inventory submissions and acting as the point of contact for the Emerging 

Technology Team. 

o  Determining whether each GenAI technology your department uses--or is planning to 

procure, borrow, or receive--qualifies for an exemption under 22J. 

o  Submitting required information for non-exempt GenAI tools under 22J through 

LogicGate 22J or an MS form. 

6 

 
 
 
 
 
 
 
 
 
",logic gate or an ms form
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",notifying dt of any updates if gen ai tools are decommissioned replaced or added to
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",your department inventory
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",supporting annual compliance reviews by the city controller
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",encourage staff to participate in gen ai related training offered by the city to understand risks
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",use cases and functionalities of specific enterprise gen ai tools if gen ai feature becomes available to staff without your department prior approval contact the vendor to learn about privacy and security implications and deactivate the functionality if needed if the tool is licensed and managed by dt report the issue immediately to the emerging technology team at
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",data protection requirements
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",the use of city data in enterprise ai tools is subject to the following restrictions
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",for copilot chat and snowflake you can use level data and below levels for chat gpt enterprise you can use level data and below levels only use phi protected health information in tools that have baa business associate agreement in place such as copilot chat and snowflake subject to your department approval
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",to verify which types of department specific data are permitted for use with city approved
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",tools always check with your department
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",do not enter any sensitive or protected data including personal information health
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",information and or financial information into public or consumer ai tools not provisioned or approved for city use
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",content entered into or generated by gen ai tools may constitute public records and may be subject to disclosure under the california public records act cpra as well as the city and county of san francisco public access and records retention requirements including the sunshine ordinance for copilot chat user inputs and ai generated content are retained for days consistent with the retention period for microsoft teams for chat gpt enterprise content is retained for days
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",data governance
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",generative ai tools depend on accurate clean and well organized data if city data is outdated inconsistent or poorly maintained ai outputs may be inaccurate or misleading
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",every department has role in
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",keeping records and metadata up to date using standardized formats per the city data management policy ensuring data is managed according to city policies
SF.pdf,7,"o  Notifying DT of any updates if GenAI tools are decommissioned, replaced or added to 

your department’s inventory.  

o  Supporting annual compliance reviews by the City Controller. 

•  Encourage staff to participate in GenAI–related training offered by the City to understand risks, 

• 

use cases, and functionalities of specific Enterprise GenAI tools. 
If a Gen-AI feature becomes available to staff without your department’s prior approval, contact 
the vendor to learn about privacy and security implications, and deactivate the functionality if 
needed. If the tool is licensed and managed by DT, report the issue immediately to the Emerging 
Technology Team at ai@sfgov.org. 

3. Data Protection Requirements 

The use of City data in Enterprise AI tools is subject to the following restrictions: 

•  For Copilot Chat and Snowflake, you can use Level 4 data and below (Levels 1–4). 
•  For ChatGPT Enterprise, you can use Level 3 data and below (Levels 1–3). 
•  Only use PHI (Protected Health Information) in tools that have a BAA (Business Associate 
Agreement) in place, such as Copilot Chat and Snowflake subject to your department’s 
approval. 

•  To verify which types of department-specific data are permitted for use with City-approved 

tools, always check with your Department.  

•  Do not enter any sensitive or protected data including personal information, health 

information, and/or financial information into public or consumer AI tools not provisioned or 
approved for City use.  

Content entered into or generated by GenAI tools may constitute public records and may be subject to 
disclosure under the California Public Records Act (CPRA), as well as the City and County of San 
Francisco’s public access and records retention requirements, including the Sunshine Ordinance. For 
Copilot Chat, user inputs and AI-generated content are retained for 30 days, consistent with the 
retention period for Microsoft Teams. For ChatGPT Enterprise, content is retained for 90 days. 

4. Data Governance  

Generative AI tools depend on accurate, clean, and well-organized data. If City data is outdated, 
inconsistent, or poorly maintained, AI outputs may be inaccurate or misleading. 

Every department has a role in: 

•  Keeping records and metadata up to date 
•  Using standardized formats per the City’s Data Management Policy 
•  Ensuring data is managed according to City policies 

Strong data governance supports reliable and fair AI usage. 

7 

 
 
 
 
 
 
 
 
",strong data governance supports reliable and fair ai usage
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",background
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",current legislative and regulatory landscape
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",since the release of the city first gen ai guidelines in december the national regulatory landscape has shifted significantly president biden executive order which prioritized ai safety security and responsible use was rescinded in early and replaced with lighter touch pro innovation policy that emphasizes deregulation and national competitiveness over public safeguards at the state level governor newsom reaffirmed california leadership in responsible ai governance with the release of report on frontier ai policy in june the report highlights growing risks like ai generated scams disinformation and threats involving dangerous materials and calls for strong practical safeguards these include enhanced transparency independent evaluations whistleblower protections and systems to track harmful incidents built on trust but verify approach the report argues that thoughtful regulation supports rather than hinders responsible innovation san francisco the home of ai
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",san francisco is at the center of the ai boom with many of the world most influential ai companies including open ai anthropic databricks as well as growing ecosystem of startups and research labs headquartered in the city as the home of ai san francisco is also on the front lines of addressing its real world impacts on residents workers and public services given the scale of innovation underway and the potential consequences of inaction the city has both responsibility and an opportunity to lead in the civic use of ai through responsible and accountable governance
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",while the city will continue to track federal and state developments it is also charting its own course under mayor lurie leadership by embracing intentional practical ai adoption grounded in ethical standards and public trust one that delivers more effective efficient and responsive services to all san franciscans
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",development of guidelines
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",the emerging technology team developed these updated gen ai focused guidelines in close coordination with the city ai advisory committee staff working group that provides guidance on the adoption governance and ethical use of emerging technologies in the city
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",contact versioning
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",the ai advisory committee will regularly update the city guidelines for generative ai use to reflect new law regulations lessons learned from application and developments in gen ai technology check these guidelines regularly for updates and bookmark to stay informed
SF.pdf,8,"5. Background 

5.1. Current Legislative and Regulatory Landscape 

Since the release of the City’s first GenAI guidelines in December 2023, the national regulatory 
landscape has shifted significantly. President Biden’s 2023 Executive Order, which prioritized AI safety, 
security, and responsible use, was rescinded in early 2025 and replaced with a lighter-touch, pro-
innovation policy that emphasizes deregulation and national competitiveness over public safeguards.  At 
the state level, Governor Newsom reaffirmed California’s leadership in responsible AI governance with 
the release of a Report on Frontier AI Policy in June 2025. The report highlights growing risks--like AI-
generated scams, disinformation, and threats involving dangerous materials--and calls for strong, 
practical safeguards. These include enhanced transparency, independent evaluations, whistleblower 
protections, and systems to track harmful incidents. Built on a “trust but verify” approach, the report 
argues that thoughtful regulation supports, rather than hinders, responsible innovation.5.2. San 
Francisco: the Home of AI 

San Francisco is at the center of the AI boom, with many of the world’s most influential AI companies--
including OpenAI, Anthropic, Databricks--as well as a growing ecosystem of startups and research labs 
headquartered in the City. As the home of AI, San Francisco is also on the front lines of addressing its 
real-world impacts on residents, workers, and public services. Given the scale of innovation underway, 
and the potential consequences of inaction, the City has both a responsibility and an opportunity to lead 
in the civic use of AI through responsible and accountable governance. 

While the City will continue to track federal and state developments, it is also charting its own course 
under Mayor Lurie's leadership by embracing intentional, practical AI adoption grounded in ethical 
standards and public trust—one that delivers more effective, efficient, and responsive services to all San 
Franciscans. 

5.3. Development of Guidelines 

The Emerging Technology Team developed these updated GenAI-focused guidelines in close 
coordination with the City’s AI Advisory Committee, a staff working group that provides guidance on the 
adoption, governance, and ethical use of emerging technologies in the City.  

6. Contact & Versioning 

The AI Advisory Committee will regularly update the City Guidelines for Generative AI Use to reflect new 
law, regulations, lessons learned from application, and developments in GenAI technology. Check these 
Guidelines regularly for updates, and bookmark to stay informed.  

For questions or help with tool selection, training opportunities, or policy interpretation please check 
with the Emerging Technology Team at ai@sfgov.org.   

8 

 
 
 
 
 
 
 
 
",for questions or help with tool selection training opportunities or policy interpretation please check with the emerging technology team at
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",this report includes content drafted with support from chat gpt enterprise gpt open ai june all content was reviewed and finalized by the emerging technology team
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",glossary algorithms are set of rules that machine follows to generate an outcome or decision
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",artificial intelligence ai refers to group of technologies that can perform complex cognitive tasks like recognizing and classifying images or powering autonomous vehicles many ai systems are built using machine learning models for task like image recognition the model learns pixel patterns from large dataset of existing images and uses these patterns to recognize and classify new images
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",auditability for ai ai where the outputs are explainable monitored and validated on regular basis
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",bard is conversational gen ai chatbot built by google
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",black box models are those where you cannot effectively determine how or why model produced specific result
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",chatbots are computer programs that simulate conversations chatbots have been around for few decades basic chatbots without gen ai use ml to understand human prompts and provide more or less scripted answers that can guide users through process gen ai chatbots can provide more human like conversational answers
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",chat gpt is conversational gen ai chatbot built by open ai
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",dall is gen ai application that can generate images based on text prompts
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",discriminative ai in contrast to gen ai discriminative ai models do not generate new content but can be used to predict quantities for example predicting home prices or to assign group membership for example classifying images
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",enterprise generative ai tool city approved gen ai tool procured and managed by the department of technology or another city department these tools are configured for city use support sensitive data with baas where applicable meet cybersecurity standards and follow strict privacy legal and data retention requirements
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",generative ai gen ai refers to group of technologies that can generate new content based on user provided prompt many are powered by llms
SF.pdf,9,"This report includes content drafted with support from ChatGPT Enterprise (GPT-4o, OpenAI, June 2025). 
All content was reviewed and finalized by the Emerging Technology Team. 

Glossary 
Algorithms: are a set of rules that a machine follows to generate an outcome or a decision. 

Artificial Intelligence (AI): refers to a group of technologies that can perform complex cognitive tasks 
like recognizing and classifying images or powering autonomous vehicles. Many AI systems are built 
using machine learning models. For a task like image recognition, the model learns pixel patterns from a 
large dataset of existing images and uses these patterns to recognize and classify new images. 

Auditability for AI: AI where the outputs are explainable, monitored and validated on a regular basis. 

Bard: is a conversational Gen AI chatbot built by Google 

Black box models: are those where you cannot effectively determine how or why a model produced a 
specific result. 

Chatbots: are computer programs that simulate conversations. Chatbots have been around for a few 
decades. Basic chatbots (without Gen AI) use ML to understand human prompts and provide more-or-
less scripted answers that can guide users through a process. Gen AI chatbots can provide more human-
like, conversational answers. 

ChatGPT: is a conversational Gen AI chatbot built by OpenAI 

Dall-e: is a Gen AI application that can generate images based on text prompts 

Discriminative AI: In contrast to Gen AI, Discriminative AI models do not generate new content but can 
be used to predict quantities (for example, predicting home prices) or to assign group membership (for 
example, classifying images). 

Enterprise Generative AI Tool: City-approved GenAI tool procured and managed by the Department of 
Technology or another City department. These tools are configured for City use, support sensitive data 
(with BAAs where applicable), meet cybersecurity standards, and follow strict privacy, legal, and data 
retention requirements. 

Generative AI (Gen AI): refers to a group of technologies that can generate new content based on a user 
provided prompt. Many are powered by LLMs. 

Large language models (LLMs): are a type of machine learning model trained using large amounts of 
text data. These models learn nuanced patterns and structure of language. This allows the model to 
understand a user generated prompt and provide a text response that is coherent. The responses are 
based on predicting the most likely word in a sequence of words and as a result, the answers are not 
always contextually correct. The training datasets used to build these models can contain gender, racial, 

9 

 
 
 
 
 
 
 
 
",large language models llms are type of machine learning model trained using large amounts of text data these models learn nuanced patterns and structure of language this allows the model to understand user generated prompt and provide text response that is coherent the responses are based on predicting the most likely word in sequence of words and as result the answers are not always contextually correct the training datasets used to build these models can contain gender racial
SF.pdf,10,"political and other biases. Since the models have learnt from biased data, their outputs can reflect these 
biases. Generative AI applications are built using these LLMs. 

Machine Learning (ML): is a method for learning the rules of an algorithm based on existing data. 

Machine learning model: is an algorithm that is built by learning patterns in existing data. For example, 
a machine learning model to predict house prices is constructed by learning from historical data on 
home prices. The model may learn that price increases with square footage, changes by neighborhood, 
and depends on the year of construction. 

Microsoft Copilot: an AI-powered assistant integrated across Microsoft 365 applications that helps users 
draft content, summarize emails, analyze data, and automate tasks. 

Model validation: methods to determine whether the outputs generated by a machine learning model 
are unbiased and accurate. 

Public or consumer Generative AI Tool: free or third-party Generative AI tool not managed by the City. 

Snowflake Cortex: a suite of built-in Generative AI and machine learning capabilities within the 
Snowflake data platform. Cortex allows users to securely analyze, summarize, and generate insights 
from data using large language models, all within the City's existing Snowflake environment. 

Training data: The dataset that is used by a machine learning model to learn the rules. 

10 

 
 
 
 
 
 
 
 
",political and other biases since the models have learnt from biased data their outputs can reflect these biases generative ai applications are built using these llms
SF.pdf,10,"political and other biases. Since the models have learnt from biased data, their outputs can reflect these 
biases. Generative AI applications are built using these LLMs. 

Machine Learning (ML): is a method for learning the rules of an algorithm based on existing data. 

Machine learning model: is an algorithm that is built by learning patterns in existing data. For example, 
a machine learning model to predict house prices is constructed by learning from historical data on 
home prices. The model may learn that price increases with square footage, changes by neighborhood, 
and depends on the year of construction. 

Microsoft Copilot: an AI-powered assistant integrated across Microsoft 365 applications that helps users 
draft content, summarize emails, analyze data, and automate tasks. 

Model validation: methods to determine whether the outputs generated by a machine learning model 
are unbiased and accurate. 

Public or consumer Generative AI Tool: free or third-party Generative AI tool not managed by the City. 

Snowflake Cortex: a suite of built-in Generative AI and machine learning capabilities within the 
Snowflake data platform. Cortex allows users to securely analyze, summarize, and generate insights 
from data using large language models, all within the City's existing Snowflake environment. 

Training data: The dataset that is used by a machine learning model to learn the rules. 

10 

 
 
 
 
 
 
 
 
",machine learning ml is method for learning the rules of an algorithm based on existing data
SF.pdf,10,"political and other biases. Since the models have learnt from biased data, their outputs can reflect these 
biases. Generative AI applications are built using these LLMs. 

Machine Learning (ML): is a method for learning the rules of an algorithm based on existing data. 

Machine learning model: is an algorithm that is built by learning patterns in existing data. For example, 
a machine learning model to predict house prices is constructed by learning from historical data on 
home prices. The model may learn that price increases with square footage, changes by neighborhood, 
and depends on the year of construction. 

Microsoft Copilot: an AI-powered assistant integrated across Microsoft 365 applications that helps users 
draft content, summarize emails, analyze data, and automate tasks. 

Model validation: methods to determine whether the outputs generated by a machine learning model 
are unbiased and accurate. 

Public or consumer Generative AI Tool: free or third-party Generative AI tool not managed by the City. 

Snowflake Cortex: a suite of built-in Generative AI and machine learning capabilities within the 
Snowflake data platform. Cortex allows users to securely analyze, summarize, and generate insights 
from data using large language models, all within the City's existing Snowflake environment. 

Training data: The dataset that is used by a machine learning model to learn the rules. 

10 

 
 
 
 
 
 
 
 
",machine learning model is an algorithm that is built by learning patterns in existing data for example machine learning model to predict house prices is constructed by learning from historical data on home prices the model may learn that price increases with square footage changes by neighborhood and depends on the year of construction
SF.pdf,10,"political and other biases. Since the models have learnt from biased data, their outputs can reflect these 
biases. Generative AI applications are built using these LLMs. 

Machine Learning (ML): is a method for learning the rules of an algorithm based on existing data. 

Machine learning model: is an algorithm that is built by learning patterns in existing data. For example, 
a machine learning model to predict house prices is constructed by learning from historical data on 
home prices. The model may learn that price increases with square footage, changes by neighborhood, 
and depends on the year of construction. 

Microsoft Copilot: an AI-powered assistant integrated across Microsoft 365 applications that helps users 
draft content, summarize emails, analyze data, and automate tasks. 

Model validation: methods to determine whether the outputs generated by a machine learning model 
are unbiased and accurate. 

Public or consumer Generative AI Tool: free or third-party Generative AI tool not managed by the City. 

Snowflake Cortex: a suite of built-in Generative AI and machine learning capabilities within the 
Snowflake data platform. Cortex allows users to securely analyze, summarize, and generate insights 
from data using large language models, all within the City's existing Snowflake environment. 

Training data: The dataset that is used by a machine learning model to learn the rules. 

10 

 
 
 
 
 
 
 
 
",microsoft copilot an ai powered assistant integrated across microsoft applications that helps users draft content summarize emails analyze data and automate tasks
SF.pdf,10,"political and other biases. Since the models have learnt from biased data, their outputs can reflect these 
biases. Generative AI applications are built using these LLMs. 

Machine Learning (ML): is a method for learning the rules of an algorithm based on existing data. 

Machine learning model: is an algorithm that is built by learning patterns in existing data. For example, 
a machine learning model to predict house prices is constructed by learning from historical data on 
home prices. The model may learn that price increases with square footage, changes by neighborhood, 
and depends on the year of construction. 

Microsoft Copilot: an AI-powered assistant integrated across Microsoft 365 applications that helps users 
draft content, summarize emails, analyze data, and automate tasks. 

Model validation: methods to determine whether the outputs generated by a machine learning model 
are unbiased and accurate. 

Public or consumer Generative AI Tool: free or third-party Generative AI tool not managed by the City. 

Snowflake Cortex: a suite of built-in Generative AI and machine learning capabilities within the 
Snowflake data platform. Cortex allows users to securely analyze, summarize, and generate insights 
from data using large language models, all within the City's existing Snowflake environment. 

Training data: The dataset that is used by a machine learning model to learn the rules. 

10 

 
 
 
 
 
 
 
 
",model validation methods to determine whether the outputs generated by machine learning model are unbiased and accurate
SF.pdf,10,"political and other biases. Since the models have learnt from biased data, their outputs can reflect these 
biases. Generative AI applications are built using these LLMs. 

Machine Learning (ML): is a method for learning the rules of an algorithm based on existing data. 

Machine learning model: is an algorithm that is built by learning patterns in existing data. For example, 
a machine learning model to predict house prices is constructed by learning from historical data on 
home prices. The model may learn that price increases with square footage, changes by neighborhood, 
and depends on the year of construction. 

Microsoft Copilot: an AI-powered assistant integrated across Microsoft 365 applications that helps users 
draft content, summarize emails, analyze data, and automate tasks. 

Model validation: methods to determine whether the outputs generated by a machine learning model 
are unbiased and accurate. 

Public or consumer Generative AI Tool: free or third-party Generative AI tool not managed by the City. 

Snowflake Cortex: a suite of built-in Generative AI and machine learning capabilities within the 
Snowflake data platform. Cortex allows users to securely analyze, summarize, and generate insights 
from data using large language models, all within the City's existing Snowflake environment. 

Training data: The dataset that is used by a machine learning model to learn the rules. 

10 

 
 
 
 
 
 
 
 
",public or consumer generative ai tool free or third party generative ai tool not managed by the city
SF.pdf,10,"political and other biases. Since the models have learnt from biased data, their outputs can reflect these 
biases. Generative AI applications are built using these LLMs. 

Machine Learning (ML): is a method for learning the rules of an algorithm based on existing data. 

Machine learning model: is an algorithm that is built by learning patterns in existing data. For example, 
a machine learning model to predict house prices is constructed by learning from historical data on 
home prices. The model may learn that price increases with square footage, changes by neighborhood, 
and depends on the year of construction. 

Microsoft Copilot: an AI-powered assistant integrated across Microsoft 365 applications that helps users 
draft content, summarize emails, analyze data, and automate tasks. 

Model validation: methods to determine whether the outputs generated by a machine learning model 
are unbiased and accurate. 

Public or consumer Generative AI Tool: free or third-party Generative AI tool not managed by the City. 

Snowflake Cortex: a suite of built-in Generative AI and machine learning capabilities within the 
Snowflake data platform. Cortex allows users to securely analyze, summarize, and generate insights 
from data using large language models, all within the City's existing Snowflake environment. 

Training data: The dataset that is used by a machine learning model to learn the rules. 

10 

 
 
 
 
 
 
 
 
",snowflake cortex suite of built in generative ai and machine learning capabilities within the snowflake data platform cortex allows users to securely analyze summarize and generate insights from data using large language models all within the city existing snowflake environment
SF.pdf,10,"political and other biases. Since the models have learnt from biased data, their outputs can reflect these 
biases. Generative AI applications are built using these LLMs. 

Machine Learning (ML): is a method for learning the rules of an algorithm based on existing data. 

Machine learning model: is an algorithm that is built by learning patterns in existing data. For example, 
a machine learning model to predict house prices is constructed by learning from historical data on 
home prices. The model may learn that price increases with square footage, changes by neighborhood, 
and depends on the year of construction. 

Microsoft Copilot: an AI-powered assistant integrated across Microsoft 365 applications that helps users 
draft content, summarize emails, analyze data, and automate tasks. 

Model validation: methods to determine whether the outputs generated by a machine learning model 
are unbiased and accurate. 

Public or consumer Generative AI Tool: free or third-party Generative AI tool not managed by the City. 

Snowflake Cortex: a suite of built-in Generative AI and machine learning capabilities within the 
Snowflake data platform. Cortex allows users to securely analyze, summarize, and generate insights 
from data using large language models, all within the City's existing Snowflake environment. 

Training data: The dataset that is used by a machine learning model to learn the rules. 

10 

 
 
 
 
 
 
 
 
",training data the dataset that is used by machine learning model to learn the rules
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",approval date review by legal counsel
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",tbd
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",chief technology officer
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",general counsel
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",purpose
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",this policy aims to establish guidelines for the responsible and secure usage of artificial intelligence hereafter referred as ai and machine learning hereafter referred as ml technologies within the district of columbia government hereafter known as district and protect the district assets workforce residents businesses and visitors from risks that may result from the inappropriate use or bias the policy covers users developers and administrators and focuses on privacy cybersecurity and data protection particularly concerning the usage of non enterprise or free ai and ml platforms
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",authority
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",dc official code et seq provides the office of the chief technology officer octo with the authority to provide information technology it services write and enforce it policies and secure the network found at
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",document
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",systems
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",district
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",and
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",can
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",this
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",the
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",be
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",for
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",it
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",applicability
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",this policy applies to all district workforce members responsible for application identity and role definition on behalf of the district and or any district agency district entity who receives enterprise services from octo in addition this policy applies to any provider and third party entity with access to district information systems networks and applications this policy also applies to any provider and third party entity with access to the district information networks and applications
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",policy
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",general guidelines
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",follow ai ml adoption and usage guidelines published by octo at
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",users developers and administrators should only use ai and ml technologies and or platforms security data protection and regulatory compliance
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",written approval of the agency director or their designee must be obtained prior to
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",utilizing agency data with any ai and or ml technologies or platforms
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",define
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",roles and responsibilities of
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",individuals and teams
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",involved
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",in ai ml
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",development deployment and monitoring establish governance board or committee responsible for overseeing ai ml risk management
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",adequate auditing and logging mechanisms should be implemented to monitor the
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",usage of ai and ml technologies
DC.pdf,1,"District of Columbia Government – Office of the Chief Technology Officer 

AI/ML Governance Policy 

Policy Number:  
Approved by 

Approval Date: 
Review by Legal Counsel: 

Effective Date:          
TBD 

___________________________
_ 
Chief Technology Officer 

__________________________
_ 
General Counsel 

1.  Purpose 

This  Policy  aims  to  establish  guidelines  for  the  responsible  and  secure  usage  of  Artificial  Intelligence 
(hereafter referred as AI) and Machine Learning (hereafter referred as ML) technologies within the District 
of  Columbia  Government  (hereafter  known  as  District)  and  protect  the  District’s  assets,  workforce, 
residents, businesses and visitors from risks that may result from the inappropriate use or bias. The policy 
covers users, developers, and administrators and focuses on privacy, cybersecurity, and data protection, 
particularly concerning the usage of non-enterprise or free AI and ML platforms. 

2.  Authority 

DC Official Code § 1-1401 et seq., provides the Office of the Chief Technology Officer (“OCTO”) with the 
authority to provide information technology (IT) services, write and enforce IT policies, and secure the 
network 
found 
at: https://code.dccouncil.us/dc/council/code/sections/1-1402.html. 

document 

systems 

District. 

and 

can 

This 

the 

be 

for 

IT 

3.  Applicability 

This policy applies to all District workforce members responsible for application identity and role definition 
on behalf of the District, and/or any District agency/District/entity who receives enterprise services from 
OCTO.  In  addition,  this  policy  applies  to  any  provider  and  third-party  entity  with  access  to  District 
information, systems, networks, and applications. 
This  Policy  also  applies  to  any  provider  and  third-party  entity  with  access  to  the  District’s  information, 
networks, and applications. 

4.  Policy  

4.1. General Guidelines 

4.1.1. 

Follow  AI/ML  Adoption  and  Usage  Guidelines  published  by  OCTO  at: 
https://octo.dc.gov/page/aiml-adoption-andor-usage-guidelines 

4.1.2.  Users, developers, and administrators should only use AI and ML technologies  and/or 
platforms  approved  by  OCTO  or  Agency  Information  technology  division  to  ensure 
security, data protection, and regulatory compliance. 

4.1.3.  Written approval of the Agency Director or their designee must be obtained prior to 

utilizing Agency data with any AI and/or ML technologies or platforms. 

4.1.4.  Define 

roles  and  responsibilities  of 

individuals  and  teams 

involved 

in  AI/ML 

4.1.5. 

development, deployment, and monitoring. 
Establish  a  governance  board  or  committee  responsible  for  overseeing  AI/ML  risk 
management. 

4.1.6.  Adequate auditing and logging mechanisms should be implemented to monitor the 

usage of AI and ML technologies. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                Page 1 of 4 

                                                              
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",acceptable use policy page of
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",prior to using any ai and ml platforms cyber and business risk assessment must be performed to evaluate the potential risks associated with data protection and compliance with relevant regulations implement measures to detect and mitigate biases in data algorithms and decision making processes regularly monitor and evaluate ai ml systems for fairness across different user groups agencies should provide education and training programs to their employees involved
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",in ai ml initiatives
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",any known or suspected policy violations or security incidents related to ai and ml
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",technologies must be immediately reported to soc and agency cio
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",data privacy and protection
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",all ai and ml activities must comply with applicable privacy laws and regulations
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",including the organization data protection policies
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",open data must be utilized when experimenting with ai and ml technology agency exploring ai ml tools or platforms should not use data classified higher than
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",level as defined in the dc data policy
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",anonymized or de identified data should be used for ai and ml purposes if utilizing
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",production data on commercial platforms or vendor proof of concepts
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",define guidelines for data collection storage and usage to ensure compliance with
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",privacy regulations data protection and data quality standards rigorously validate and test your ai ml models before deploying them implement robust evaluation methods to assess performance fairness and potential risks associated with the models ensure proper data governance practices are in place including data quality control data privacy and security measures be aware of biases and potential discrimination in the data used for training ml models
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",unauthorized uses and specific prohibitions
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",the usage of non enterprise or free ai and ml platforms is discouraged as they may pose potential risks to data security and privacy
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",unauthorized creation transmission or usage of ai and ml generated content unauthorized sharing or uploading of dc agency data to third party platforms utilizing ai and ml tools to bypass security and or regulatory controls
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",sharing personal or sensitive data without appropriate consent
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",integrating public facing or internal application with ai platforms without proper disclosure
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",create or re create content that violates copyright and or violates the district
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",government ethical standards
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",create materials related to illegal weapons terrorist activities and any other illegal
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",activities or activities otherwise prohibited etc
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",cyber security and continuous monitoring
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",implement mechanisms for continuous monitoring and evaluation of ai ml systems to identify and address emerging risks establish processes for auditing reporting and addressing non compliance regularly review and update the risk management framework to adapt to changing technological regulatory and organizational requirements implement robust security measures to protect ai ml systems from adversarial attacks data breaches and unauthorized access regularly assess vulnerabilities and apply appropriate security patches and updates
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",exemptions exceptions to this policy shall be requested in writing to the agency cio and the request will be escalated to the octo chief information security officer ciso
DC.pdf,2,"4.1.7. 

Prior to using any AI and ML platforms, a cyber and business risk assessment must be 
performed  to  evaluate  the  potential  risks  associated  with  data  protection,  and 
compliance with relevant regulations. 
Implement measures to detect and mitigate biases in data, algorithms, and decision-
making processes. 
Regularly monitor and evaluate AI/ML systems for fairness across different user groups. 
4.1.9. 
4.1.10.  Agencies should provide education and training programs to their employees involved 

4.1.8. 

in AI/ML initiatives. 

4.1.11.  Any  known  or  suspected  policy  violations  or  security  incidents  related  to  AI  and  ML 

technologies must be immediately reported to SOC (soc@dc.gov) and Agency CIO. 

4.2. Data Privacy and Protection 

4.2.1.  All  AI  and  ML  activities  must  comply  with  applicable  privacy  laws  and  regulations, 

including the organization's data protection policies. 

4.2.2.  Open Data must be utilized when experimenting with AI and ML technology. 
4.2.3.  Agency’s exploring AI/ML tools or platforms should not use data classified higher than 

“Level 0” as defined in the DC Data Policy. 

4.2.4.  Anonymized  or  de-identified  data  should  be  used  for  AI  and  ML  purposes  if  utilizing 

production data on commercial platforms or vendor proof of concepts. 

4.2.5.  Define guidelines for data collection, storage, and usage to ensure compliance with 

4.2.6. 
4.2.7. 

4.2.8. 

4.2.9. 

privacy regulations, data protection, and data quality standards. 
Rigorously validate and test your AI/ML models before deploying them.  
Implement robust evaluation methods to assess performance, fairness, and potential 
risks associated with the models. 
Ensure proper data governance practices are in place, including data quality control, 
data privacy, and security measures.  
Be aware of biases and potential discrimination in the data used for training ML models. 

4.3. Unauthorized Uses and Specific Prohibitions 

4.3.1. 

The usage of non-enterprise or free AI and ML platforms is discouraged, as they may 
pose potential risks to data security and privacy. 

4.3.2.  Unauthorized creation, transmission, or usage of AI and ML generated content. 
4.3.3.  Unauthorized sharing or uploading of DC Agency data to third-party platforms. 
4.3.4. 
4.3.5.  Utilizing AI and ML tools to bypass security and/or regulatory controls. 
4.3.6. 

Sharing Personal or sensitive data without appropriate consent. 

Integrating  public  facing  or  internal  application  with  AI  platforms  without  proper 
disclosure. 

4.3.7.  Create  or  re-create  content  that  violates  copyright  and/or  violates  the  District 

Government ethical standards. 

4.3.8.  Create  materials  related  to  illegal  weapons,  terrorist  activities,  and  any  other  illegal 

activities or activities otherwise prohibited, etc. 

4.4. Cyber Security and Continuous Monitoring 

4.4.1. 

4.4.2. 
4.4.3. 

4.4.4. 

4.4.5. 

Implement mechanisms for continuous monitoring and evaluation of AI/ML systems to 
identify and address emerging risks. 
Establish processes for auditing, reporting, and addressing non-compliance. 
Regularly review and update the risk management framework to adapt to changing 
technological, regulatory, and organizational requirements. 
Implement robust security measures to protect AI/ML systems from adversarial attacks, 
data breaches, and unauthorized access.  
Regularly assess vulnerabilities and apply appropriate security patches and updates. 

5.  Exemptions 
Exceptions to this policy shall be requested in writing to the Agency CIO and the request will be escalated 
to the OCTO Chief Information Security Officer (“CISO”). 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 2 of 4 

 
 
 
 
",acceptable use policy page of
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",definitions
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",the definition of the terms used in this document can be found in the glossary section of the octo policy website and appendix below
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",sanctions
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",to safeguard district government technology and other resources violators of this policy may be denied access to district government computing and network resources and may be subject to other disciplinary action within district government violators of this policy will be handled in accordance with the district government established disciplinary procedures and or applicable collective bargaining agreement octo may suspend block or restrict access to computing resources and accounts independent of such procedures when it reasonably appears necessary to do so to protect the integrity confidentiality or availability of district government computing and network resources or to protect the district government from liability
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",if violations of this policy are discovered that are illegal activities the district government may
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",notify appropriate authorities
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",the district government reserves the right to pursue appropriate legal actions to recover any
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",financial losses suffered because of the violations of this policy
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",references
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",nist special publication sp revision security and privacy controls for federal
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",information systems and districts april
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",nist special publication ai
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",revision history
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",date
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",reviewed by
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",action
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",next review date
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",contact information
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",questions concerning this policy may be directed to the office of the chief technology officer at the or
DC.pdf,3,"6.  Definitions 

The definition of the terms used in this document can be found in the Glossary section of the OCTO Policy 
Website and appendix 1 below. 

 Sanctions  

7. 
To safeguard District Government technology and other resources, violators of this policy may be denied 
access  to  District  Government  computing  and  network  resources  and  may  be  subject  to  other 
disciplinary action within District Government.  Violators of this policy will be handled in accordance with 
the District Government’s established disciplinary procedures and/or applicable Collective Bargaining 
Agreement.  OCTO  may  suspend,  block,  or  restrict  access  to  computing  resources  and  accounts, 
independent of such procedures, when it reasonably appears necessary to do so to protect the integrity, 
confidentiality, or availability of District Government computing and network resources, or to protect the 
District Government from liability. 

7.1. If violations of this Policy are discovered that are illegal activities, the District Government may 

notify appropriate authorities. 

7.2. The District Government reserves the right to pursue appropriate legal actions to recover any 

financial losses suffered because of the violations of this policy. 

8.  References  

9.1. NIST  Special  Publication  (SP)  800-53  Revision  4  –  Security  and  Privacy  Controls  for  Federal 

Information Systems and Districts (April 2013).  

9.2. NIST Special Publication (AI) 100-1 

9.  Revision History. 

Date 

Reviewed by 

Action 

Effective Date 

Next Review Date 

10.  Contact Information 

Questions concerning this policy may be directed to the Office of the Chief Technology Officer 
at the 202-727-2277 or infosecpolicy@dc.gov. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 3 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",acceptable use policy page of
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",appendix
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",appendix terms and definitions
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",term
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",district government information systems
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",district government workforce
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",district government technology resources
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",ai
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",ml
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",definition
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",technology systems owned or paid for by district government funds including but not limited to internet intranet extranet related systems computer and other digital equipment software operating systems storage media network accounts providing electronic mail and other messaging and systems that enable web browsing and file transfer
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",source octo
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",individuals who perform district government functions and who are classified as employees volunteers contractors and interns
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",source octo technology resources owned or paid for by district government funds including but not limited to internet intranet extranet related systems computer and other digital equipment software operating systems storage media network accounts providing electronic mail and other messaging and systems that enable web browsing and file transfer
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",source octo artificial intelligence ai refers to the capability of device to perform functions that are normally associated with human intelligence such as reasoning learning and self improvement
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",source nist machine learning ml refers to the ability of systems to learn and improve from available data without explicit programming
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",source octo
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",enterprise ai and ml platform
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",the enterprise ai and ml platform refers to the authorized licensed or internally developed ai and ml technologies approved for use within the organization
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",non enterprise or free ai and ml platforms
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",non enterprise or free ai and ml platforms refer to external platforms or tools not officially sanctioned or
DC.pdf,4,"APPENDIX 

Appendix 1 – Terms and Definitions: 

Term 

District 
Government 
Information 
Systems 

District 
Government 
Workforce 

District 
Government 
Technology 
Resources 

AI 

ML 

Definition 

Technology systems owned or paid for by District Government funds, including, but 
not limited to Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 

Individuals who perform District Government functions and who are classified as 
employees, volunteers, contractors, and interns. 

Source: OCTO 
Technology resources owned or paid for by District Government funds, including, but 
not limited to:  Internet/Intranet/Extranet-related systems, computer and other digital 
equipment, software, operating systems, storage media, network accounts providing 
electronic mail and other messaging, and systems that enable web browsing, and 
file transfer. 

Source: OCTO 
Artificial Intelligence (AI) refers to the capability of a device to perform functions that 
are normally associated with human intelligence such as reasoning, learning, and 
self-improvement. 

Source: NIST 
Machine Learning (ML) refers to the ability of systems to learn and improve from 
available data without explicit programming. 

Source: OCTO 

Enterprise AI and 
ML Platform 

The enterprise AI and ML platform refers to the authorized, licensed, or internally 
developed AI and ML technologies approved for use within the organization. 

Non-Enterprise or 
Free AI and ML 
Platforms 

Non-enterprise or free AI and ML platforms refer to external platforms or tools not 
officially sanctioned or approved by OCTO or your Agency for AI and ML purposes. 

_____________________________________________________________________________________ 
Acceptable Use Policy                                                                                                                                 Page 4 of 4 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
",acceptable use policy page of
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",purpose the city of tempe established the ethical artificial intelligence ai policy to affirm tempe commitment to responsible and ethical use of ai through the principles that ensure transparency fairness accountability and the protection of individual rights in all ai related activities conducted by the city of tempe being intentional in our adoption and use of ai technologies will drive innovation support increased efficiencies in operations and improved experiences for community engagement this policy outlines the principles guidelines and procedures governing the responsible and ethical use of ai technologies within tempe
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",scope this policy applies to the design development and deployment of ai for
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",all departments agencies employees contractors and stakeholders involved in the development deployment and utilization of ai within tempe categories of ai inclusive of predictive analytics machine learning deep learning generative ai and automated decision making all cases where ai functionality is known to be included such as new tools for existing products new products being considered for use or where ai technology is developed by tempe employees contractors partner agencies or other stakeholders
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",policy statement the city of tempe is committed to designing developing and deploying ai technologies in responsible and ethical manner we recognize that ai has the potential to significantly impact society and drive innovation and we believe that it is our duty to ensure that its development adoption and use align with the principles of fairness transparency accountability and respect for human rights with this in mind we hereby establish our ethical ai policy outlining the principles and guidelines that will govern our ai initiatives
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",purpose and scope we will clearly define the problem the ai technology would solve
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",including the purpose and the scope of application
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",human centered approach we will prioritize the well being safety and dignity of individuals and communities affected by ai technology we use we will strive to understand and address the needs and values of humans promoting ai technologies that enhance human capabilities foster inclusion and contribute to the overall betterment of society
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",human responsibility we will clearly define the roles and responsibilities of human
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",operators in utilizing ai systems including their training requirements and obligations for monitoring and intervening in system decisions
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",human ai collaboration we will encourage collaboration between humans and ai
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",systems leveraging the strengths of both to enhance decision making processes and ensure that ultimate control remains with humans
Tempe.pdf,1,"Ethical Artificial Intelligence (AI) Policy

I.

Purpose
The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s 
commitment to responsible and ethical use of AI through the principles that ensure transparency, 
fairness, accountability, and the protection of individual rights in all AI-related activities conducted 
by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive 
innovation, support increased efficiencies in operations and improved experiences for community 
engagement. This policy outlines the principles, guidelines, and procedures governing the 
responsible and ethical use of AI technologies within Tempe.

II.

Scope
This policy applies to the design, development, and deployment of AI for:







All departments, agencies, employees, contractors, and stakeholders involved in the 
development, deployment, and utilization of AI within Tempe. 
Categories of AI inclusive of predictive analytics, machine learning, deep learning, 
generative AI, and automated decision making 
All cases where AI functionality is known to be included, such as new tools for existing 
products, new products being considered for use or where AI technology is developed by 
Tempe employees, contractors, partner agencies or other stakeholders. 

III.

Policy Statement
The City of Tempe is committed to designing, developing, and deploying AI technologies in a 
responsible and ethical manner. We recognize that AI has the potential to significantly impact 
society and drive innovation, and we believe that it is our duty to ensure that its development, 
adoption, and use align with the principles of fairness, transparency, accountability, and respect for 
human rights. With this in mind, we hereby establish our ethical AI policy, outlining the principles 
and guidelines that will govern our AI initiatives:

1. Purpose and Scope. We will clearly define the problem the AI technology would solve 

including the purpose and the scope of application.  

2. Human-Centered Approach: We will prioritize the well-being, safety, and dignity of 
individuals and communities affected by AI technology we use. We will strive to 
understand and address the needs and values of humans, promoting AI technologies 
that enhance human capabilities, foster inclusion, and contribute to the overall 
betterment of society.

3. Human Responsibility: We will clearly define the roles and responsibilities of human 

operators in utilizing AI systems, including their training requirements and obligations 
for monitoring, and intervening in system decisions. 

4. Human-AI Collaboration: We will encourage collaboration between humans and AI 

systems, leveraging the strengths of both to enhance decision-making processes and 
ensure that ultimate control remains with humans.

5. Fairness and Avoidance of Bias: We will actively work to eliminate biases and ensure 
fairness in our design, development, and deployment of AI technology. We will take 

5/31/2023

",fairness and avoidance of bias we will actively work to eliminate biases and ensure fairness in our design development and deployment of ai technology we will take
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",steps to prevent discrimination protect privacy and mitigate the risks of unfair or unjust outcomes resulting from ai algorithms we will continuously assess and mitigate potential biases throughout the ai lifecycle
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",transparency and explainability we will strive to make our selection design
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",development and deployment of ai technology transparent and explainable to the best of our abilities we will clearly disclose where individuals are interacting with ai or interacting with ai generated content we will provide clear documentation and accessible information about the functioning and purpose of the ai technologies we use enabling users stakeholders and those who are subject to decisions informed by ai to understand and question the decision making processes involved
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",accountability and oversight we will establish standards for accountability and oversight throughout the selection design development and deployment of ai technology we will be responsible for the actions and impacts of the ai technology we use and we will implement strategies to identify mitigate and rectify any potential harms or unintended consequences resulting from their use we will proactively engage in ongoing monitoring evaluation and auditing to ensure compliance with ethical standards
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",data privacy and security we will maintain the highest standards of data privacy and
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",security in our ai initiatives we will handle personal data in accordance with applicable policy laws and regulations and we will implement robust safeguards to protect data from unauthorized access misuse or breaches
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",collaboration and public engagement we will actively engage with stakeholders such
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",as users experts policymakers and community organizations to solicit diverse perspectives and feedback on the ai technology under consideration or currently used we will seek to foster collaboration and share knowledge to address ethical challenges and ensure that ai technologies benefit society as whole
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",continuous monitoring and ethical improvement we will continuously strive to
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",improve the ethical aspects of our ai technology through research innovation and learning from our experiences we will keep abreast of emerging ethical guidelines and best practices adapting our policies and practices accordingly
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",training programs we will provide training programs and resources to employees involved in ai system development and utilization promoting ai literacy ethical considerations privacy protection and responsible ai practices
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",compliance and legal frameworks we will comply with applicable laws standards and regulations related to ai and data protection we will actively support the development of ethical ai regulations and frameworks that align with our principles and contribute to the responsible use of ai technology
Tempe.pdf,2,"steps to prevent discrimination, protect privacy, and mitigate the risks of unfair or 
unjust outcomes resulting from AI algorithms. We will continuously assess and mitigate 
potential biases throughout the AI lifecycle.

6. Transparency and Explainability: We will strive to make our selection, design, 

development, and deployment of AI technology transparent and explainable to the 
best of our abilities. We will clearly disclose where individuals are interacting with AI or 
interacting with AI generated content. We will provide clear documentation and 
accessible information about the functioning and purpose of the AI technologies we 
use, enabling users, stakeholders and those who are subject to decisions informed by 
AI to understand and question the decision-making processes involved.

7. Accountability and Oversight: We will establish standards for accountability and 
oversight throughout the selection, design, development, and deployment of AI 
technology. We will be responsible for the actions and impacts of the AI technology we 
use, and we will implement strategies to identify, mitigate and rectify any potential 
harms or unintended consequences resulting from their use. We will proactively 
engage in ongoing monitoring, evaluation, and auditing to ensure compliance with 
ethical standards.

8. Data Privacy and Security: We will maintain the highest standards of data privacy and 

security in our AI initiatives. We will handle personal data in accordance with applicable 
policy, laws, and regulations, and we will implement robust safeguards to protect data 
from unauthorized access, misuse, or breaches. 

9. Collaboration and Public Engagement: We will actively engage with stakeholders, such 

as users, experts, policymakers, and community organizations, to solicit diverse 
perspectives and feedback on the AI technology under consideration or currently used. 
We will seek to foster collaboration and share knowledge to address ethical challenges 
and ensure that AI technologies benefit society as a whole.

10. Continuous Monitoring and Ethical Improvement: We will continuously strive to 

improve the ethical aspects of our AI technology through research, innovation, and 
learning from our experiences. We will keep abreast of emerging ethical guidelines and 
best practices, adapting our policies and practices accordingly.

11. Training Programs: We will provide training programs and resources to employees 
involved in AI system development and utilization, promoting AI literacy, ethical 
considerations, privacy protection, and responsible AI practices.

12. Compliance and Legal Frameworks: We will comply with applicable laws, standards and 
regulations related to AI and data protection. We will actively support the development 
of ethical AI regulations and frameworks that align with our principles and contribute 
to the responsible use of AI technology.

This ethical AI policy statement reflects our commitment to responsible and ethical AI. We 
recognize that ethical considerations are paramount, and we will hold ourselves accountable to 
these principles as we work towards creating AI technologies that benefit humanity and contribute 
positively to our collective future. 

5/31/2023

",this ethical ai policy statement reflects our commitment to responsible and ethical ai we recognize that ethical considerations are paramount and we will hold ourselves accountable to these principles as we work towards creating ai technologies that benefit humanity and contribute positively to our collective future
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",ai governance
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",departments shall
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",define clear objectives and goals in support of adopting an ai solution and the
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",intended use of the solution
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",collaborate with information technology to complete the artificial intelligence review process and will implement any mitigation strategies identified during the review
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",conduct semiannual reviews of implemented ai solutions
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",technology and innovation steering committee shall
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",establish mechanisms for ongoing monitoring and evaluation of ai solutions to
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",ensure compliance with this policy and relevant laws and regulations
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",develop reporting mechanisms for ai related activities including regular audits
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",to assess policy compliance and identify areas for improvement
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",define consequences for non compliance with this policy including disciplinary
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",actions or termination of contracts and establish remedial measures to address violations or failures of ai systems
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",support public awareness campaigns and educational initiatives to inform and engage the public on ai related activities their purpose and potential impacts
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",information technology shall
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",collaborate with departments to develop the artificial intelligence review
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",process
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",collaborate with departments to complete the artificial intelligence review
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",process and semiannual review
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",provide training programs and resources to employees involved in ai system development and utilization promoting ai literacy ethical considerations privacy protection and responsible ai practices
Tempe.pdf,3,"IV.

AI Governance

1. Departments shall

a) Define clear objectives and goals in support of adopting an AI solution and the 

intended use(s) of the solution. 

b) Collaborate with Information Technology to complete the Artificial Intelligence 
Review process and will implement any mitigation strategies identified during 
the review. 

c) Conduct semiannual reviews of implemented AI solutions. 

2. Technology and Innovation Steering Committee shall

a) Establish mechanisms for ongoing monitoring and evaluation of AI solutions to 

ensure compliance with this policy and relevant laws and regulations.

b) Develop reporting mechanisms for AI-related activities, including regular audits 

to assess policy compliance and identify areas for improvement.

c) Define consequences for non-compliance with this policy, including disciplinary 

actions or termination of contracts, and establish remedial measures to 
address violations or failures of AI systems.

d) Support public awareness campaigns and educational initiatives to inform and 
engage the public on AI-related activities, their purpose, and potential impacts.

3.

Information Technology shall

a) Collaborate with departments to develop the Artificial Intelligence Review 

Process. 

b) Collaborate with departments to complete the Artificial Intelligence Review 

process and semiannual review.

c) Provide training programs and resources to employees involved in AI system 
development and utilization, promoting AI literacy, ethical considerations, 
privacy protection, and responsible AI practices.

This policy will be periodically reviewed and updated as necessary to address emerging challenges, 
technological advancements, and changes in legal or regulatory frameworks related to AI.

5/31/2023

",this policy will be periodically reviewed and updated as necessary to address emerging challenges technological advancements and changes in legal or regulatory frameworks related to ai
Boston.pdf,1,"City of Boston Interim Guidelines
for Using Generative AI

Version 1.1
Prepared by Santiago Garces, Chief Information Ofﬁcer, City of Boston
Published: 5/18/2023
Applies to: all City agencies and departments with the exception of Boston Public
Schools

Purpose

Generative AI is a set of relatively new technologies that leverages large (very large)
volumes of data along with some machine learning (ML) techniques to produce content
based on inputs from the users known as prompts. The new content can be written (e.g.
ChatGPT or Bard), or visual (e.g. Dall-E). These tools are evolving rapidly, and are still the
subject of active research: improving our understanding of how they actually work, and
the impacts of their use in society. These tools are not actual intelligence in the human
sense, rather, they are very sophisticated models that predict what the language, text, or
video that satisﬁes the prompt should be. Because of their impact and potential
usefulness, as well as the risks and dangers, these guidelines serve as an interim
resource for employees of the City of Boston.

Generative AI is a tool. We are responsible for the outcomes of our tools. For example, if
autocorrect unintentionally changes a word - changing the meaning of something we
wrote, we are still responsible for the text. Technology enables our work, it does not
excuse our judgment nor our accountability.

These guidelines should be replaced in the future with policies and standards. But we want to
encourage responsible experimentation and we encourage you to try these tools for
yourselves to understand their potential. The Department of Innovation and Technology will
support events and workshops that can support people and teams interested in learning more
about these technologies. For the time being we encourage you to watch this video from
Innovate.US about how to get started with generative AI in government:
https://bit.ly/InnovateUS-AI
You can also share your experiences, thoughts, and concerns via this online form:
https://forms.gle/BptUcVhRdnTwHdxJ7

",city of boston interim guidelines for using generative ai
Boston.pdf,1,"City of Boston Interim Guidelines
for Using Generative AI

Version 1.1
Prepared by Santiago Garces, Chief Information Ofﬁcer, City of Boston
Published: 5/18/2023
Applies to: all City agencies and departments with the exception of Boston Public
Schools

Purpose

Generative AI is a set of relatively new technologies that leverages large (very large)
volumes of data along with some machine learning (ML) techniques to produce content
based on inputs from the users known as prompts. The new content can be written (e.g.
ChatGPT or Bard), or visual (e.g. Dall-E). These tools are evolving rapidly, and are still the
subject of active research: improving our understanding of how they actually work, and
the impacts of their use in society. These tools are not actual intelligence in the human
sense, rather, they are very sophisticated models that predict what the language, text, or
video that satisﬁes the prompt should be. Because of their impact and potential
usefulness, as well as the risks and dangers, these guidelines serve as an interim
resource for employees of the City of Boston.

Generative AI is a tool. We are responsible for the outcomes of our tools. For example, if
autocorrect unintentionally changes a word - changing the meaning of something we
wrote, we are still responsible for the text. Technology enables our work, it does not
excuse our judgment nor our accountability.

These guidelines should be replaced in the future with policies and standards. But we want to
encourage responsible experimentation and we encourage you to try these tools for
yourselves to understand their potential. The Department of Innovation and Technology will
support events and workshops that can support people and teams interested in learning more
about these technologies. For the time being we encourage you to watch this video from
Innovate.US about how to get started with generative AI in government:
https://bit.ly/InnovateUS-AI
You can also share your experiences, thoughts, and concerns via this online form:
https://forms.gle/BptUcVhRdnTwHdxJ7

",version prepared by santiago garces chief information officer city of boston published applies to all city agencies and departments with the exception of boston public schools
Boston.pdf,1,"City of Boston Interim Guidelines
for Using Generative AI

Version 1.1
Prepared by Santiago Garces, Chief Information Ofﬁcer, City of Boston
Published: 5/18/2023
Applies to: all City agencies and departments with the exception of Boston Public
Schools

Purpose

Generative AI is a set of relatively new technologies that leverages large (very large)
volumes of data along with some machine learning (ML) techniques to produce content
based on inputs from the users known as prompts. The new content can be written (e.g.
ChatGPT or Bard), or visual (e.g. Dall-E). These tools are evolving rapidly, and are still the
subject of active research: improving our understanding of how they actually work, and
the impacts of their use in society. These tools are not actual intelligence in the human
sense, rather, they are very sophisticated models that predict what the language, text, or
video that satisﬁes the prompt should be. Because of their impact and potential
usefulness, as well as the risks and dangers, these guidelines serve as an interim
resource for employees of the City of Boston.

Generative AI is a tool. We are responsible for the outcomes of our tools. For example, if
autocorrect unintentionally changes a word - changing the meaning of something we
wrote, we are still responsible for the text. Technology enables our work, it does not
excuse our judgment nor our accountability.

These guidelines should be replaced in the future with policies and standards. But we want to
encourage responsible experimentation and we encourage you to try these tools for
yourselves to understand their potential. The Department of Innovation and Technology will
support events and workshops that can support people and teams interested in learning more
about these technologies. For the time being we encourage you to watch this video from
Innovate.US about how to get started with generative AI in government:
https://bit.ly/InnovateUS-AI
You can also share your experiences, thoughts, and concerns via this online form:
https://forms.gle/BptUcVhRdnTwHdxJ7

",purpose
Boston.pdf,1,"City of Boston Interim Guidelines
for Using Generative AI

Version 1.1
Prepared by Santiago Garces, Chief Information Ofﬁcer, City of Boston
Published: 5/18/2023
Applies to: all City agencies and departments with the exception of Boston Public
Schools

Purpose

Generative AI is a set of relatively new technologies that leverages large (very large)
volumes of data along with some machine learning (ML) techniques to produce content
based on inputs from the users known as prompts. The new content can be written (e.g.
ChatGPT or Bard), or visual (e.g. Dall-E). These tools are evolving rapidly, and are still the
subject of active research: improving our understanding of how they actually work, and
the impacts of their use in society. These tools are not actual intelligence in the human
sense, rather, they are very sophisticated models that predict what the language, text, or
video that satisﬁes the prompt should be. Because of their impact and potential
usefulness, as well as the risks and dangers, these guidelines serve as an interim
resource for employees of the City of Boston.

Generative AI is a tool. We are responsible for the outcomes of our tools. For example, if
autocorrect unintentionally changes a word - changing the meaning of something we
wrote, we are still responsible for the text. Technology enables our work, it does not
excuse our judgment nor our accountability.

These guidelines should be replaced in the future with policies and standards. But we want to
encourage responsible experimentation and we encourage you to try these tools for
yourselves to understand their potential. The Department of Innovation and Technology will
support events and workshops that can support people and teams interested in learning more
about these technologies. For the time being we encourage you to watch this video from
Innovate.US about how to get started with generative AI in government:
https://bit.ly/InnovateUS-AI
You can also share your experiences, thoughts, and concerns via this online form:
https://forms.gle/BptUcVhRdnTwHdxJ7

",generative ai is set of relatively new technologies that leverages large very large volumes of data along with some machine learning ml techniques to produce content based on inputs from the users known as prompts the new content can be written chat gpt or bard or visual dall these tools are evolving rapidly and are still the subject of active research improving our understanding of how they actually work and the impacts of their use in society these tools are not actual intelligence in the human sense rather they are very sophisticated models that predict what the language text or video that satisfies the prompt should be because of their impact and potential usefulness as well as the risks and dangers these guidelines serve as an interim resource for employees of the city of boston
Boston.pdf,1,"City of Boston Interim Guidelines
for Using Generative AI

Version 1.1
Prepared by Santiago Garces, Chief Information Ofﬁcer, City of Boston
Published: 5/18/2023
Applies to: all City agencies and departments with the exception of Boston Public
Schools

Purpose

Generative AI is a set of relatively new technologies that leverages large (very large)
volumes of data along with some machine learning (ML) techniques to produce content
based on inputs from the users known as prompts. The new content can be written (e.g.
ChatGPT or Bard), or visual (e.g. Dall-E). These tools are evolving rapidly, and are still the
subject of active research: improving our understanding of how they actually work, and
the impacts of their use in society. These tools are not actual intelligence in the human
sense, rather, they are very sophisticated models that predict what the language, text, or
video that satisﬁes the prompt should be. Because of their impact and potential
usefulness, as well as the risks and dangers, these guidelines serve as an interim
resource for employees of the City of Boston.

Generative AI is a tool. We are responsible for the outcomes of our tools. For example, if
autocorrect unintentionally changes a word - changing the meaning of something we
wrote, we are still responsible for the text. Technology enables our work, it does not
excuse our judgment nor our accountability.

These guidelines should be replaced in the future with policies and standards. But we want to
encourage responsible experimentation and we encourage you to try these tools for
yourselves to understand their potential. The Department of Innovation and Technology will
support events and workshops that can support people and teams interested in learning more
about these technologies. For the time being we encourage you to watch this video from
Innovate.US about how to get started with generative AI in government:
https://bit.ly/InnovateUS-AI
You can also share your experiences, thoughts, and concerns via this online form:
https://forms.gle/BptUcVhRdnTwHdxJ7

",generative ai is tool we are responsible for the outcomes of our tools for example if autocorrect unintentionally changes word changing the meaning of something we wrote we are still responsible for the text technology enables our work it does not excuse our judgment nor our accountability
Boston.pdf,1,"City of Boston Interim Guidelines
for Using Generative AI

Version 1.1
Prepared by Santiago Garces, Chief Information Ofﬁcer, City of Boston
Published: 5/18/2023
Applies to: all City agencies and departments with the exception of Boston Public
Schools

Purpose

Generative AI is a set of relatively new technologies that leverages large (very large)
volumes of data along with some machine learning (ML) techniques to produce content
based on inputs from the users known as prompts. The new content can be written (e.g.
ChatGPT or Bard), or visual (e.g. Dall-E). These tools are evolving rapidly, and are still the
subject of active research: improving our understanding of how they actually work, and
the impacts of their use in society. These tools are not actual intelligence in the human
sense, rather, they are very sophisticated models that predict what the language, text, or
video that satisﬁes the prompt should be. Because of their impact and potential
usefulness, as well as the risks and dangers, these guidelines serve as an interim
resource for employees of the City of Boston.

Generative AI is a tool. We are responsible for the outcomes of our tools. For example, if
autocorrect unintentionally changes a word - changing the meaning of something we
wrote, we are still responsible for the text. Technology enables our work, it does not
excuse our judgment nor our accountability.

These guidelines should be replaced in the future with policies and standards. But we want to
encourage responsible experimentation and we encourage you to try these tools for
yourselves to understand their potential. The Department of Innovation and Technology will
support events and workshops that can support people and teams interested in learning more
about these technologies. For the time being we encourage you to watch this video from
Innovate.US about how to get started with generative AI in government:
https://bit.ly/InnovateUS-AI
You can also share your experiences, thoughts, and concerns via this online form:
https://forms.gle/BptUcVhRdnTwHdxJ7

",these guidelines should be replaced in the future with policies and standards but we want to encourage responsible experimentation and we encourage you to try these tools for yourselves to understand their potential the department of innovation and technology will support events and workshops that can support people and teams interested in learning more about these technologies for the time being we encourage you to watch this video from innovate us about how to get started with generative ai in government us ai you can also share your experiences thoughts and concerns via this online form uc vh rdn tw hdx
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",these are some of the types of uses that could be beneficial additional good practices and examples can be found at the end of this document
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",writing memo in government we often have to write short documents that
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",present an argument why policy should be adopted or decision should be made for instance try the prompt in chat gpt bard and other generative text tools write memo to the chief innovation officer about the potential
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",benefits of the use of generative ai in city government
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",writing job description generative ai can produce job descriptions that aggregate and average parts of similar job descriptions giving you very good generalized version of job description for instance try the prompt in chat gpt bard and other generative text tools write the job description for chief information officer of
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",large city
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",principles
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",empowerment
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",the use of ai should support the work of our workforce to deliver better safer
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",more efficient and equitable services and products to our residents
Boston.pdf,2,"Sample Use Cases

These are some of the types of uses that could be beneﬁcial. Additional good practices and
examples can be found at the end of this document.

1. Writing a memo. In government we often have to write short documents that

present an argument why a policy should be adopted or a decision should be made.
For instance try the prompt in ChatGPT, Bard, and other generative text tools:

Unset

Write a memo to the Chief Innovation Officer about the potential

benefits of the use of generative AI in city government.

2. Writing a job description. Generative AI can produce job descriptions that aggregate
and average parts of similar job descriptions, giving you a very good generalized
version of a job description. For instance try the prompt in ChatGPT, Bard, and
other generative text tools:

Unset

Write the job description for a Chief Information Officer of a

large city

Principles

Empowerment

● The use of AI should support the work of our workforce to deliver better, safer,

more efﬁcient and equitable services and products to our residents.

● We rely and trust in our public sector professionals to do the right thing given the
right tools and guidance. You will need to exercise your judgment to make sure we

",we rely and trust in our public sector professionals to do the right thing given the right tools and guidance you will need to exercise your judgment to make sure we
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",get the benefits from the tools while avoiding the negative impacts for the city and its constituents inclusion and respect
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",the use and development of ai should support the development of work that repairs damage done to racial and ethnic minorities people of all genders and sexual orientations people of all ages people with disabilities and others our work should uplift these communities and connect them more effectively with the resources they need to thrive
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",everything we do regardless of the tools are reflection of the city and ourselves we are stewards of the public and we will use tools respectfully and responsibly
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",transparency and accountability
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",we embrace the possibilities of technology and community we acknowledge that we do not have all the answers nor can we foresee all consequences but when we act transparently we build trust and we gain the ability to learn collectively we also acknowledge that experimentation might have costs and impacts in of
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",itself including the usage of power greenhouse gas emissions being purposeful and accountable to these impacts is important
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",innovation and risk management
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",we understand that there is value to be had in the use of technology particularly new generative ai but there are also risks some of which will not be apparent or fully understood upfront
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",we embrace culture of responsible experimentation where we maintain control and understanding of the use of new tools while we develop new uses that drive efficiency delight civic dialogue or other outcomes in service of our residents
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",privacy and security
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",every technology tool that we use has an impact on the security of our overall
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",environment and the privacy and digital rights of our constituents
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",public purpose
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",the best known of these new tools are developed for commercial purposes while
Boston.pdf,3,"get the beneﬁts from the tools while avoiding the negative impacts for the City and
its constituents.
Inclusion and Respect

● The use and development of AI should support the development of work that
repairs damage done to racial and ethnic minorities, people of all genders and
sexual orientations, people of all ages, people with disabilities, and others. Our
work should uplift these communities and connect them more effectively with the
resources they need to thrive.

● Everything we do, regardless of the tools, are a reﬂection of the City and ourselves.
We are stewards of the public, and we will use tools respectfully and responsibly.

Transparency and accountability

● We embrace the possibilities of technology and community. We acknowledge that
we do not have all the answers nor can we foresee all consequences. But when we
act transparently, we build trust and we gain the ability to learn collectively.
● We also acknowledge that experimentation might have costs and impacts in of

itself including the usage of power, greenhouse gas emissions. Being purposeful
and accountable to these impacts is important.

Innovation and Risk Management

● We understand that there is value to be had in the use of technology, particularly
new generative AI, but there are also risks, some of which will not be apparent or
fully understood upfront.

● We embrace a culture of responsible experimentation, where we maintain control
and understanding of the use of new tools while we develop new uses that drive
efﬁciency, delight, civic dialogue or other outcomes in service of our residents.

Privacy and Security

● Every technology tool that we use has an impact on the security of our overall

environment, and the privacy and digital rights of our constituents.

Public Purpose

● The best known of these new tools are developed for commercial purposes. While

they can be adapted for mission-driven work by public professionals, it is
important to maintain service to the public at the center of our work.

",they can be adapted for mission driven work by public professionals it is important to maintain service to the public at the center of our work
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",guidelines
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",fact check and review all content generated by ai especially if it will be used in public communication or decision making
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",why while generative ai can rapidly produce clear prose the information and
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",content might be inaccurate outdated or simply made up it is your responsibility to verify that the information is accurate by independently researching claims made by the ai what to look for
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",inaccurate information including links and references to events or facts bias in the positions or information we want to make sure that vulnerable populations are not harmed by these technologies think about how racial and ethnic minorities women non binary people with disabilities or others could be portrayed or impacted by the content
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",disclose that you have used ai to generate the content you should also include the version and type of model you used open ai gpt vs google bard you should include reference as footer to the fact that you used generative ai
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",why even when you use ai minimally disclosure builds trust through transparency
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",and it might help others catch errors
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",suggestions document how you used the model the prompts you used etc it could be helpful to you and your colleagues to better understand how you can use these technologies better and more safely
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",sample credit line this description was generated by chat gpt and edited by
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",santiago garces
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",sample credit line this text was summarized using google bard
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",do not share sensitive or private information in the prompts
Boston.pdf,4,"Guidelines

Fact Check and review all content generated by AI, especially if it will
be used in public communication or decision making.

● Why: While Generative AI can rapidly produce clear prose, the information and

content might be inaccurate, outdated, or simply made up. It is your responsibility
to verify that the information is accurate by independently researching claims
made by the AI.
● What to look for:

○ Inaccurate information including links and references to events or facts.
○ Bias in the positions or information. We want to make sure that vulnerable
populations are not harmed by these technologies. Think about how racial
and ethnic minorities, women, non-binary, people with disabilities or others
could be portrayed or impacted by the content.

Disclose that you have used AI to generate the content. You should also
include the version and type of model you used (e.g, Open AI's GPT 3.5
vs Google's Bard). You should include a reference as a footer to the fact
that you used generative AI:

● Why: even when you use AI minimally, disclosure builds trust through transparency

and it might help others catch errors.

● Suggestions: document how you used the model, the prompts you used etc. it could
be helpful to you and your colleagues to better understand how you can use these
technologies better and more safely.

● Sample credit line: “This description was generated by ChatGPT 3.5 and edited by

Santiago Garces”

● Sample credit line: “This text was summarized using Google Bard”

Do not share sensitive or private information in the prompts

● Why: data including prompts used in generative AI might be used by the companies
that power these systems. Any information that includes personally identifying
information about our residents, other public servants, etc. could inadvertently be
shared with others. Basically if you wouldn’t share with other people or want to put
the prompt in a public place, avoid sharing the information in the prompt. If you
have an application that requires sensitive information to be used with a generative

",why data including prompts used in generative ai might be used by the companies that power these systems any information that includes personally identifying information about our residents other public servants etc could inadvertently be shared with others basically if you wouldn share with other people or want to put the prompt in public place avoid sharing the information in the prompt if you have an application that requires sensitive information to be used with generative
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",ai contact do it so we can help you provision access to enterprise secure resources to do so
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",more examples do and don ts
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",these are some suggestions on the kinds of uses that seem to be particularly useful for city uses by encouraging responsible experimentation we are hoping to expand the potential uses while minimizing risks
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",drafting documents or letters
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",generative ai provides great opportunity to get started on memo letters job descriptions note that when creating prompt for chat gpt for this context it can consider including any specific format preferences such as essay bullet points outline or dialogue additionally you can request the use of specific keywords or phrases or technical terms to be included or avoided in the response this will help chat gpt provide you with more tailored and efficient response to your request
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",example generate guidelines for the use of chat gpt at the city of boston example write letter requesting support for funding digital equity initiatives in
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",the next budget session
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",example you can ask chat gpt to generate letters that express points of view
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",specified in the prompt this might allow you to understand an issue from different perspectives
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",example you can ask generative ai to help you write more effective version of prompt you can say help me write better prompt to insert the initial objective of the prompt do
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",try to be specific in the prompt if you give more context the answer
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",becomes more relevant
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",edit and review the content regardless of how the content was authored
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",you and the city will bear responsibility over its use in the public
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",don ts
Boston.pdf,5,"AI, contact DoIT so we can help you provision access to enterprise secure resources to
do so.

More Examples, Do’s and Don’ts:

These are some suggestions on the kinds of uses that seem to be particularly useful for
City uses. By encouraging responsible experimentation we are hoping to expand the
potential uses, while minimizing risks.

Drafting documents or letters:

Generative AI provides a great opportunity to get started on a memo, letters, job
descriptions. Note that when creating a prompt for ChatGPT for this context, it can
consider including any speciﬁc format preferences such as essay, bullet points, outline or
dialogue. Additionally, you can request the use of speciﬁc keywords or phrases, or
technical terms to be included or avoided in the response. This will help ChatGPT provide
you with a more tailored and efﬁcient response to your request.

● Example: generate guidelines for the use of ChatGPT at the City of Boston
● Example: write a letter requesting support for funding digital equity initiatives in

the next budget session.

● Example: you can ask Chat GPT to generate letters that express points of view

speciﬁed in the prompt. This might allow you to understand an issue from different
perspectives.

● Example: You can ask Generative AI to help you write a more effective version of a
prompt. You can say “ help me write a better prompt to [insert the initial objective
of the prompt].
Do’s:

1. Try to be speciﬁc in the prompt. If you give more context, the answer

becomes more relevant.

2. Edit and review the content. Regardless of how the content was authored,

you and the City will bear responsibility over its use in the public.

Don’ts:

1. Do not include conﬁdential information in the prompt.
2. Do not rely on generative AI to provide accurate answers.

",do not include confidential information in the prompt do not rely on generative ai to provide accurate answers
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",do not use generative ai to create communication regarding sensitive topics for instance renowned institution was criticized for using generative ai to write press release regarding shooting
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",drafting content in plain language
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",generative ai can help you write clearer and simpler language you can use the prompt to indicate the reading level or audience for text
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",example use chat gpt or bard to write version of the declaration of independence of the united states for person in elementary school
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",example use tools such as aiseo wordtune or others to modify sentence these tools are similar to thesaurus but for sentences and often allow you to optimize for the length of the sentence or the audience do
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",specify in the prompt if you have specific audience in mind try different prompts or request different versions of the same sentence
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",until you find what works best
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",you can pass the output of the text by readability app that can identify
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",challenging sentences as well as the reading level for the text
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",don ts
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",do not include confidential information in the prompt review the text to ensure that the language is inclusive and respectful the models might use language or patterns that appear regularly but that might exclude some people for instance model might suggest dear sir ma am does not include non binary people and could be replaced with dear colleague or dear neighbor
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",drafting content in other languages
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",ai can help you draft communications in another language it is not well documented the extent to which chat gpt and other models can use other languages but users report over languages being available for chat gpt including some native american languages
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",example use chat gpt to translate these guidelines into spanish and french just
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",ask translate your text into spanish and french
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",example you can ask generative ai in what language some text is written in just
Boston.pdf,6,"3. Do not use generative AI to create communication regarding sensitive
topics. For instance, a renowned institution was criticized for using
generative AI to write a press release regarding a shooting.

Drafting Content In Plain Language

Generative AI can help you write clearer and simpler language. You can use the prompt to
indicate the reading level or audience for a text.

● Example: use ChatGPT or Bard to write a version of the Declaration of
Independence of the United States for a person in elementary school.

● Example: use tools such as AISEO, Wordtune or others to modify a sentence. These
tools are similar to a thesaurus but for sentences and often allow you to optimize
for the length of the sentence, or the audience.
Do’s:

1. Specify in the prompt if you have a speciﬁc audience in mind.
2. Try different prompts, or request different versions of the same sentence

until you ﬁnd what works best.

3. You can pass the output of the text by a readability app that can identify

challenging sentences, as well as the reading level for the text.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Review the text to ensure that the language is inclusive and respectful. The
models might use language or patterns that appear regularly, but that might
exclude some people. For instance, a model might suggest: “Dear Sir/Ma'am”
does not include non-binary people, and could be replaced with “Dear
Colleague” or “Dear neighbor”.

Drafting Content In Other Languages

AI can help you draft communications in another language. It is not well documented the
extent to which ChatGPT and other models can use other languages, but users report over
50 languages being available for ChatGPT, including some native american languages.

● Example: use ChatGPT to translate these guidelines into Spanish and French, just

ask “translate [your text] into Spanish and French.”

● Example: you can ask generative AI in what language some text is written in, just

ask “what language is [original language] written in?”

",ask what language is original language written in
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",do
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",try different languages chat gpt bard and other models were trained using
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",text from many languages chat gpt told me it didn speak quechua in quechua
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",you can also ask generative ai to perform similar tasks as the ones in this
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",document in other languages such as summarizing text etc
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",don ts
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",do not include confidential information in the prompt do not use content generated in language you do not understand before
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",consulting someone with proficiency in the language you still need to check for accuracy bias etc
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",language generated in other languages might be confusing to people who
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",speak different regional dialects do not assume that some text will be easily understood by all speakers use the prompt to get regional diction
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",summarizing text
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",generative ai does great job of summarizing longer pieces of text into summaries if you have few pages that you want to condense into few bullet points or you have been struggling with converting long set of notes into paragraph these tools could be very helpful
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",example copy notes taken from meeting to generate short summary of the
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",meeting
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",example summarize citizen comments in response to an engagement example write paragraph summary of page report example use fathom wudpecker or the transcript tools in google hangouts to
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",transcribe audio into text you can then summarize the text further using generative ai this summarization is included in some of these tools
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",don ts
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",do not include confidential information in the prompt make sure you have
Boston.pdf,7,"Do’s:

1. Try different languages. ChatGPT, Bard and other models were trained using

text from many languages. ChatGPT told me it didn’t speak Quechua in
Quechua!

2. You can also ask generative AI to perform similar tasks as the ones in this

document in other languages, such as summarizing text, etc.

Don'ts:

1. Do not include conﬁdential information in the prompt.
2. Do not use content generated in a language you do not understand before

consulting someone with proﬁciency in the language. You still need to check
for accuracy, bias, etc.

3. Language generated in other languages might be confusing to people who

speak different regional dialects. Do not assume that some text will be easily
understood by all speakers. Use the prompt to get regional diction.

Summarizing Text

Generative AI does a great job of summarizing longer pieces of text into summaries. If you
have a few pages that you want to condense into a few bullet points, or you have been
struggling with converting a long set of notes into a paragraph, these tools could be very
helpful.

● Example: copy notes taken from a meeting to generate a short summary of the

meeting.

● Example: summarize citizen comments in response to an engagement
● Example: write a paragraph summary of a 5 page report.
● Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to

transcribe audio into text. You can then summarize the text further using
generative AI. This summarization is included in some of these tools.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have

2.

deleted conﬁdential information from your notes or other inputs.
If you plan on making a decision based on the summary, you should read the
entire document(s) to make sure you did not miss or miss characterized the
original document.

",deleted confidential information from your notes or other inputs if you plan on making decision based on the summary you should read the entire document to make sure you did not miss or miss characterized the original document
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",be aware that the resulting summary might have biases as it will tend to
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",present language that is more frequent in the data used to train the model you can use changes to the prompt to enhance the results by suggesting that the result incorporates perspectives from marginalized groups even better you can engage with some individuals in these communities to better understand their perspectives on the text generated
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",summarizing audio
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",coding programming generative ai can be great at producing snippets or even help you build more complex components of code
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",example write code in python that extracts tables in pdf into pandas data
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",frame
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",this can make it possible for less technical people including interns and student
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",workers to get to work on technical projects
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",do
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",explore new languages and libraries but you should understand the code and read
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",the documentation of the relevant components before using it
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",you might have to adjust parameters and your environment to make the
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",suggestions from the ai model work generative ai can help you get started but often you will have to edit before the code works
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",don ts
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",do not include confidential information in the prompt as in development best practices do not include passwords confidential keys or other proprietary information in your code or in the prompts
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",you should understand what the code is doing before using it in production you should understand the use of new libraries and dependencies and become
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",familiar with vulnerabilities and other security considerations of using language or library
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",images audio and videos
Boston.pdf,8,"3. Be aware that the resulting summary might have biases as it will tend to

present language that is more frequent in the data used to train the model.
You can use changes to the prompt to enhance the results by suggesting
that the result incorporates perspectives from marginalized groups. Even
better, you can engage with some individuals in these communities to better
understand their perspectives on the text generated.

Summarizing Audio

Coding/Programming
Generative AI can be great at producing snippets or even help you build more complex
components of code.

● Example: write code in Python that extracts tables in a PDF into a Pandas data

frame.

● This can make it possible for less technical people, including interns and student

workers, to get to work on technical projects.

Do’s:

1. Explore new languages and libraries - but you should understand the code and read

the documentation of the relevant components before using it.

2. You might have to adjust parameters, and your environment to make the

suggestions from the AI model work. Generative AI can help you get started, but
often you will have to edit before the code works.

Don’ts:

1. Do not include conﬁdential information in the prompt. As in development best
practices: do not include passwords, conﬁdential keys, or other proprietary
information in your code or in the prompts.

2. You should understand what the code is doing before using it in production.
3. You should understand the use of new libraries and dependencies, and become

familiar with vulnerabilities and other security considerations of using a language
or a library.

Images, Audio, and Videos

Generative AI can produce images,audio, and videos based on prompts. This can support
the creation of appealing or insightful communication resources.

",generative ai can produce images audio and videos based on prompts this can support the creation of appealing or insightful communication resources
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",example make an image in medieval style of residents connecting to the wifi in
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",order to create appealing collateral for digital equity campaign
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",example create training video that walks residents on how to schedule bulky
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",item pick up by providing the script of the video
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",example write jingle or song to remind them to switch to boston community
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",choice electricity to switch to renewable energy do
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",visual audio and video communication can be powerful tool to communicate with others and get across message generative ai can empower you to use these tools beyond your artistic skills
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",use generative ai as tool to create drafts or mock ups that allow you to
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",communicate more effectively with graphic designers videographers and other creative workers
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",contact your department or agency public information officer about the image
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",audio or video before publishing or using it they have expertise on best practices in accessibility branding etc
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",engaging with members of the equity cabinet or community organizations that represent groups that might be referenced or impacted by this content getting their perspective in respectful way can help you identify when content might be hurtful discriminatory or misinterpreted
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",don ts
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",do not include confidential information in the prompt make sure you have deleted
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",confidential information from your notes or other inputs some confidential information could include people faces people voices their identifications license plates etc particularly those who have not provided their consent
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",make sure the outputs of the generative ai will not be offensive or harmful towards people particularly vulnerable residents that are susceptible to harm including ethnic and racial groups diverse gender individuals and others make sure that any content adheres to the city brand guidelines
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",resources
Boston.pdf,9,"● Example: make an image in a medieval style of residents connecting to the wiﬁ in

order to create appealing collateral for a digital equity campaign.

● Example: create a training video that walks residents on how to schedule a bulky

item pick up, by providing the script of the video.

● Example: write a jingle or song to remind them to switch to Boston’s Community

Choice Electricity to switch to 100% renewable energy.
Do’s:

1. Visual,audio and video communication can be a powerful tool to communicate with
others and get across a message. Generative AI can empower you to use these tools
beyond your artistic skills.

2. Use generative AI as a tool to create drafts or mock ups that allow you to

communicate more effectively with graphic designers, videographers, and other
creative workers.

3. Contact your department or agency’s public information ofﬁcer about the image,

audio, or video before publishing or using it. They have expertise on best practices
in accessibility, branding, etc.

4. Engaging with members of the Equity Cabinet, or community organizations that
represent groups that might be referenced or impacted by this content. Getting
their perspective, in a respectful way, can help you identify when content might be
hurtful, discriminatory, or misinterpreted.

Don’ts:

1. Do not include conﬁdential information in the prompt: make sure you have deleted

conﬁdential information from your notes or other inputs. Some conﬁdential
information could include: people’s faces, people’s voices, their identiﬁcations,
license plates, etc. Particularly, those who have not provided their consent.

2. Make sure the outputs of the generative AI will not be offensive or harmful towards
people, particularly vulnerable residents that are susceptible to harm including
ethnic and racial groups, diverse gender individuals, and others.
3. Make sure that any content adheres to the City’s Brand Guidelines

Resources

You can contact the Department of Innovation and Technology [doit@boston.gov] to learn
more about generative AI.
You can also contact the Mayor’s Ofﬁce of Arts and Culture [arts@boston.gov] or to the
Mayor’s Ofﬁce of New Urban Mechanics [newurbanmechanics@boston.gov] if you want to

",you can contact the department of innovation and technology to learn more about generative ai you can also contact the mayor office of arts and culture or to the mayor office of new urban mechanics if you want to
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",discuss important questions about the impact of generative ai on the arts and on our society
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",the following resources include external links we do not endorse any one of these resources
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",reddit chat gpt sub reddit gpt great explanation on the mathematical principles behind generative language models
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",stephen wolfram what is chat gpt doing and why does it work stephen wolfram writings writings stephenwolfram com what is chatgpt doing and why does it work
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",ai principles from microsoft aprimaryr
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",ai principles from google
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",nist ai risk framework
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",critical analysis of large language models major paper that predicted much of the harms risks we are experiencing now
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",acknowledgements
Boston.pdf,10,"discuss important questions about the impact of generative AI on the arts and on our
society.

The following resources include external links. We do not endorse any one of these
resources.

Reddit, ChatGPT sub reddit: https://www.reddit.com/r/ChatGPT/
A great explanation on the mathematical principles behind generative language models:

Stephen Wolfram (2023), ""What Is ChatGPT Doing ... and Why Does It Work?,"" Stephen
Wolfram Writings.
writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.

AI Principles from Microsoft:
https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6

AI Principles from Google:
https://ai.google/principles/

NIST AI Risk Framework:
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

A critical analysis of large language models (major paper that predicted much of the
harms/risks we are experiencing now)
https://dl.acm.org/doi/10.1145/3442188.3445922

Acknowledgements

The development of these guidelines has beneﬁted from the contributions of academic,
community, and City of Boston team members.
Special thanks to Beth Noveck, Director of the Burnes Center for Social Change at
Northeastern University; Saiph Savage, Director of the Civic AI Lab at Northeastern
University; Catherine D’Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly
Lucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at
Harvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor’s
Ofﬁce of New Urban Mechanics; Jerry Kelley, project manager at the Department of
Innovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation
and Technology.

",the development of these guidelines has benefited from the contributions of academic community and city of boston team members special thanks to beth noveck director of the burnes center for social change at northeastern university saiph savage director of the civic ai lab at northeastern university catherine ignazio director of the data feminism lab at mit kimberly lucas professor of the practice at northeastern university mitch weiss professor at harvard business school alejandro jimenez jaramillo michael evans from the mayor office of new urban mechanics jerry kelley project manager at the department of innovation and technology kerry jordan chief of staff at the department of innovation and technology
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",page of
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",section purpose
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",providing framework and guidelines for the use of artificial intelligence ai in the city of lebanon will help address the different risks associated with ai there are variety of benefits that result from using ai systems but there must be guidelines in place for them to be used responsibly the city of lebanon is committed to safe and responsible uses of ai by its employees
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",section scope
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",this policy applies to all departments and or divisions of the city of lebanon
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",section definitions
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",algorithmic discrimination occurs when automated systems contribute to unjustified different treatment or impacts disfavoring people based on their race skin color national or ethnic origin cultural group language gender identity or expression sexual orientation mental or physical ability age religious or political opinion or activity economic status immigration status or housing status
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",artificial intelligence ai is type of computer science which deals with computer systems that perform tasks which usually require human intelligence such as reasoning problem solving perception and language
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",bing ai is ai software that allows individuals to chat with an intelligent chatbot and generate various types of content bing ai is part of microsoft search engine
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",chatbot is ai software that seeks to mimic human conversation through interactions via text or voice
Lebanon.pdf,1,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 1 of 7

Approved by:  

Section 1.0: Purpose

Providing a framework and guidelines for the use of artificial intelligence ( AI)  in the
City of Lebanon will help address the different risks associated with AI.   There are a
variety of benefits that result from using AI systems,  but there must be guidelines
in place for them to be used responsibly.   The City of Lebanon is committed to safe
and responsible uses of AI by its employees. 

Section 2.0: Scope

This policy applies to all departments and/ or divisions of the City of Lebanon. 

Section 3.0: Definitions

3.1 Algorithmic Discrimination occurs when automated systems contribute to
unjustified different treatment or impacts disfavoring people based on their race, 
skin color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status. 

3.2 Artificial Intelligence ( AI) is a type of computer science which deals with
computer systems that perform tasks which usually require human intelligence, 
such as reasoning,  problem solving,  perception,  and language. 

3.3 Bing AI is AI software that allows individuals to chat with an intelligent chatbot
and generate various types of content.  Bing AI is part of Microsoft’ s search engine.     

3.4 Chatbot is AI software that seeks to mimic human conversation through
interactions via text or voice.   

3.5 ChatGPT stands for Chat Generative Pre- trained Transformer.  It is a complex
machine learning model that is able to carry out natural language generation ( NLG) 
tasks with such a high level of accuracy that the model can pass a Turing Test.   It is
based on the ""GPT ( Generative Pre- training Transformer)  architecture,  which is a
type of neural network designed for natural language processing tasks.”   ChatGPT is
an AI chatbot that uses natural language processing to create humanlike
conversational dialogue.   The language model can respond to questions and
compose various written content,  including articles,  social media posts,  essays, 

",chat gpt stands for chat generative pre trained transformer it is complex machine learning model that is able to carry out natural language generation nlg tasks with such high level of accuracy that the model can pass turing test it is based on the gpt generative pre training transformer architecture which is type of neural network designed for natural language processing tasks chat gpt is an ai chatbot that uses natural language processing to create humanlike conversational dialogue the language model can respond to questions and compose various written content including articles social media posts essays
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",page of
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",code and emails chat gpt chat gpt and chat gpt are the current models available to the public to use
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",generative ai uses both computer algorithms and large volumes of data to create new content such as audio code images and videos
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",sensitive data or personally identifying information pii as defined in protected
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",technology review committee trc this committee consists of the cyber services director chief innovation officer and asset manager the committee works across all departments to review and audit any technology including but not limited to software technology and ai
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",section policy detail
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",transparency and accountability
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",city employees must be transparent and accountable when using ai technology following these guidelines are essential in ensuring the responsible and ethical use of ai systems within the city operations the following are important guidelines concerning transparency and accountability
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",information disclosure city employees shall make efforts to disclose the use
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",of ai systems in the workplace when and where appropriate employees must be open to sharing information when appropriate about the data being used algorithms that are applied and decision making criteria when disclosing the use of ai in the workplace employees should utilize the guidance provided in this policy
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",for example if an employee uses chat gpt or bing to get ideas for news article or gather helpful information they would not need to disclose that they used ai to assist in their work just like they would not disclose they used spellchecker to check for grammatical errors
Lebanon.pdf,2,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 2 of 7

Approved by:  

code and emails.   ChatGPT- 3,  ChatGPT- 3.5, and ChatGPT- 4 are the current models
available to the public to use. 

3.6 Generative AI uses both computer algorithms and large volumes of data to
create new content,  such as audio,  code,  images,  and videos.    

3.7 Sensitive Data or Personally Identifying Information ( PII) (as defined in
ADM- 450 Securing Sensitive Information)  is information that is private and must be
protected. 

3.8 Technology Review Committee ( TRC) –  This committee consists of the
Cyber Services Director,  Chief Innovation Officer,  and Asset Manager.  The
committee works across all departments to review and audit any technology, 
including but not limited to software,  technology,  and AI.  

Section 4.0: Policy Detail

4.1 Transparency and Accountability

City employees must be transparent and accountable when using AI technology. 
Following these guidelines are essential in ensuring the responsible and ethical use
of AI systems within the city's operations.   The following are important guidelines
concerning transparency and accountability:   

a.) Information Disclosure:  City employees shall make efforts to disclose the use

of AI systems in the workplace when and where appropriate.  Employees
must be open to sharing information,  when appropriate,  about the data being
used,  algorithms that are applied,  and decision- making criteria.  When
disclosing the use of AI in the workplace,  employees should utilize the
guidance provided in this policy.  

For example,  if an employee uses ChatGPT or Bing to get ideas for a news
article or gather helpful information,  they would not need to disclose that
they used AI to assist in their work,  just like they would not disclose they
used a spellchecker to check for grammatical errors.  

However,  a process that is fully automated without human intervention
would need to provide appropriate disclosures.  For example,  if an AI was
programmed to read an agenda and then summarize the contents to post on

",however process that is fully automated without human intervention would need to provide appropriate disclosures for example if an ai was programmed to read an agenda and then summarize the contents to post on
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",page of
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",social media without any human oversight the post would need to include that the text was ai generated
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",auditing the city will regularly engage in monitoring evaluating and auditing its ai systems to ensure that the city is complying with ethical standards and legal standards reviews will be conducted by the cyber service department in coordination with the technology review committee
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",responsible decision making city employees shall use ai as tool to assist
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",in the decision making process rather than relying completely on an automated output however there will be circumstances where decision making will be completely automated such as answers provided by chatbot see examples section
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",public engagement and feedback city employees should make efforts to
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",gather the questions concerns and other types of feedback from lebanon residents regarding ai systems used by the city of lebanon by doing so this can enhance fairness and inclusion in the responsible decision making process
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",privacy and security
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",in some cases the ai systems that employees use have direct impact on the security of the surrounding community while there is significant value in ai technology there are also potential risks involved with some risks not being particularly obvious or understood in order to secure and protect the digital rights of our community members the following must be done
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",data protection protecting the personally identifying confidential and
Lebanon.pdf,3,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 3 of 7

Approved by:  

social media without any human oversight,  the post would need to include
that the text was AI- generated.  

b.) Auditing:  The City will regularly engage in monitoring,  evaluating,  and
auditing its AI systems to ensure that the City is complying with ethical
standards and legal standards.  Reviews will be conducted by the Cyber
Service Department in coordination with the Technology Review Committee.   

c.)  Responsible Decision- Making:  City employees shall use AI as a tool to assist

in the decision- making process,  rather than relying completely on an
automated output. However,  there will be circumstances where decision-
making will be completely automated,  such as answers provided by a chatbot
see examples Section 4.1.a).  

d.) Public Engagement and Feedback:  City employees should make efforts to

gather the questions,  concerns,  and other types of feedback from Lebanon
residents regarding AI systems used by the City of Lebanon.  By doing so, 
this can enhance fairness and inclusion in the responsible decision- making
process.   

4.2 Privacy and Security

In some cases,  the AI systems that employees use have a direct impact on the
security of the surrounding community.   While there is significant value in AI
technology,  there are also potential risks involved,  with some risks not being
particularly obvious or understood.   In order to secure and protect the digital rights
of our community members,  the following must be done: 

A.) Data Protection:  Protecting the personally identifying,  confidential and

financial information of the City of Lebanon’ s citizens,  employees,  and other
entities should be a priority for every City employee.   The proper handling
and storage of personal data is necessary,  and there needs to be data
protection policies and procedures in place to ensure there is no unauthorized
access,  use,  or disclosure of sensitive information.   City employees will
handle sensitive data in accordance with applicable laws,  policies,  and
procedures,  as well as enforce strong safeguards to protect data from being
accessed by unauthorized users.   

",financial information of the city of lebanon citizens employees and other entities should be priority for every city employee the proper handling and storage of personal data is necessary and there needs to be data protection policies and procedures in place to ensure there is no unauthorized access use or disclosure of sensitive information city employees will handle sensitive data in accordance with applicable laws policies and procedures as well as enforce strong safeguards to protect data from being accessed by unauthorized users
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",page of
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",education and awareness management and supervisory staff are
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",encouraged to help city employees who use ai by educating and raising awareness about the risks associated with using these types of systems
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",fairness and respect
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",using ai should not in any way discriminate against any individual race skin color national or ethnic origin cultural group language gender identity or expression sexual orientation mental or physical ability age religious or political opinion or activity economic status immigration status or housing status in accordance with city code welcoming lebanon every action carried out by city of lebanon employees is reflection upon the city and thus it is imperative to act respectfully and responsibly for this to be achieved the following must be done
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",avoiding bias any biases that are identified must be addressed and
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",corrective actions should be taken bias can come in many forms such as biased training data sampling bias and stereotyping societal biases the city of lebanon will continuously strive to act ethically when using ai technology and will make improvements as needed
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",preventing algorithmic discrimination ai systems should be used in an
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",equitable way and should avoid algorithmic discrimination any instance of discrimination against protected class as delineated in city code shall be reported in accordance with
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",promoting inclusion city employees should use ai systems fairly and shall not discriminate against any individual including underrepresented and disadvantaged groups within datasets can help prevent biases and promote inclusion
Lebanon.pdf,4,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 4 of 7

Approved by:  

b.) Education and Awareness:  Management and supervisory staff are

encouraged to help City employees who use AI by educating and raising
awareness about the risks associated with using these types of systems.    

4.3 Fairness and Respect

Using AI should not in any way discriminate against any individual’ s race,  skin
color,  national or ethnic origin,  cultural group,  language,  gender identity or
expression,  sexual orientation,  mental or physical ability,  age,  religious or political
opinion or activity,  economic status,  immigration status,  or housing status.   In
accordance with City Code 185 Welcoming Lebanon,  every action carried out by
City of Lebanon employees is a reflection upon the City,  and thus it is imperative to
act respectfully and responsibly.   For this to be achieved,  the following must be
done:  

a.) Avoiding Bias:   Any biases that are identified must be addressed and

corrective actions should be taken.   Bias can come in many forms,  such as, 
biased training data,  sampling bias,  and stereotyping/ societal biases.   The
City of Lebanon will continuously strive to act ethically when using AI
technology and will make improvements as needed.  

b.) Preventing Algorithmic Discrimination:  AI systems should be used in an

equitable way and should avoid algorithmic discrimination.   Any instance of
discrimination against a protected class,  as delineated in City Code 185,  shall
be reported in accordance with ADM- 126.1.     

c.)  Promoting Inclusion:   City employees should use AI systems fairly and shall
not discriminate against any individual.   Including underrepresented and
disadvantaged groups within datasets can help prevent biases and promote
inclusion. 

4.4 Human Alternatives

",human alternatives
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",page of
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",the appropriate amount of human oversight should be used when ai systems fail to meet their expected duties transparent effective and timely human intervention shall be applied when it is necessary to do so
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",human intervention city employees should be able to override ai systems when appropriate and find corrective solutions and remedies to problems that arise human intervention shall be effective accessible fair and shall not present an unreasonable burden on those intervening with the ai technology the public deserves back up human intervention system where human review is initiated in case of an ai system failure or threat caused by the system itself
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",transparent human alternatives transparency should be held as high priority by city employees and this will help individuals understand the decision making processes behind ai systems transparency allows humans to make reasonable judgements and take responsibility for the results
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",effective and timely human alternatives human intervention should be
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",effective and timely in order to adequately address any ai challenges this will allow ai system failures and threats to be resolved quickly and efficiently
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",an example of human alternative to ai is demonstrated in the city chatbot where person looking for answers is also offered human alternatives for communication such as phone numbers and emails of staff members or ask leb nh service that connects residents with the right person
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",training
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",cyber services in coordination with the trc will provide training opportunities for city employees to provide them with the necessary knowledge to use ai technology safely and appropriately employees who utilize ai in their work shall be trained on those systems
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",training resources and tools the city of lebanon will provide employees
Lebanon.pdf,5,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 5 of 7

Approved by:  

The appropriate amount of human oversight should be used when AI systems fail to
meet their expected duties.   Transparent,  effective,  and timely human intervention
shall be applied when it is necessary to do so.   

a.) Human Intervention:  City employees should be able to override AI systems
when appropriate and find corrective solutions and remedies to problems
that arise.   Human intervention shall be effective,  accessible,  fair,  and shall
not present an unreasonable burden on those intervening with the AI
technology.   The public deserves a back- up human intervention system
where human review is initiated in case of an AI system failure or a threat
caused by the system itself.   

b.) Transparent Human Alternatives:  Transparency should be held as a high
priority by City employees,  and this will help individuals understand the
decision- making processes behind AI systems.   Transparency allows humans
to make reasonable judgements and take responsibility for the results. 

c.)  Effective and Timely Human Alternatives:  Human intervention should be

effective and timely in order to adequately address any AI challenges.   This
will allow AI system failures and threats to be resolved quickly and
efficiently.  

An example of human alternative to AI is demonstrated in the City’s chatbot
where a person looking for answers is also offered human alternatives for
communication,  such as phone numbers and emails of staff members,  or Ask
LebNH,  a service that connects residents with the right person. 

4.5 Training

Cyber Services in coordination with the TRC will provide training opportunities for
City employees to provide them with the necessary knowledge to use AI technology
safely and appropriately.   Employees who utilize AI in their work shall be trained on
those systems.  

a.) Training Resources and Tools:  The City of Lebanon will provide employees

with access to a variety of training resources to promote AI literacy,  and will
assist in providing the necessary knowledge in order to safely,  efficiently,  and
responsibly use AI technology in the workplace.  The TRC shall serve in a role
to provide guidance to city staff and the use of AI.  

",with access to variety of training resources to promote ai literacy and will assist in providing the necessary knowledge in order to safely efficiently and responsibly use ai technology in the workplace the trc shall serve in role to provide guidance to city staff and the use of ai
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",page of
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",policy enforcement non compliance with these guidelines may result in
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",disciplinary action or restriction of access and possibly even termination of employment it is important to act safely responsibly and to use degree of caution when using ai technology
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",technology review committee
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",the technology review committee is tasked with reviewing this policy and proposing revisions to the city manager the trc will closely monitor the evolving use of ai and issues related to the use of ai in the city as well as the broader cyber environment
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",section procedures under development
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",section references charter code state statutes
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",city of boston interim guidelines for using generative ai
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",guidelines for using generative ai boston gov
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",city of lebanon cyber policy
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",city of lebanon city code chapter chapter welcoming lebanon
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",city of lebanon city policy
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",laserfiche com
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",city of seattle use of generative artificial intelligence in city of seattle
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",seattle it memo nlc org
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",city of tempe ethical artificial intelligence ai policy
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",ethical artifical intelligence policy docx document cloud
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",white house blueprint for an ai bill of rights
Lebanon.pdf,6,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 6 of 7

Approved by:  

b.) Policy Enforcement:  Non- compliance with these guidelines may result in

disciplinary action or restriction of access,  and possibly even termination of
employment.   It is important to act safely,  responsibly,  and to use a degree
of caution when using AI technology.      

4.6 Technology Review Committee

The Technology Review Committee is tasked with reviewing this policy and
proposing revisions to the City Manager.  The TRC will closely monitor the evolving
use of AI and issues related to the use of AI in the City as well as the broader
cyber environment.  

Section 5.0: Procedures
Under development. 

Section 6.0: References ( Charter/ Code/ State Statutes) 

1.  City of Boston,  Interim Guidelines for Using Generative AI

Guidelines for Using Generative AI (boston. gov)   

2.  City of Lebanon,  Cyber Policy ADM- 450 Securing Sensitive Information

3.  City of Lebanon,  City Code Chapter 185
Chapter 185 Welcoming Lebanon

4.  City of Lebanon,  City Policy ADM- 126.1

ADM- 126.1_Complaints &  Investigations_ Effective 01-01-2021
laserfiche. com) 

5.  City of Seattle,  Use of Generative Artificial Intelligence in City of Seattle

Seattle IT Memo ( nlc.org) 

6.  City of Tempe,  Ethical Artificial Intelligence ( AI)  Policy

ETHICAL_ ARTIFICAL_ INTELLIGENCE_ POLICY. DOCX -  DocumentCloud

7.  White House,  Blueprint for an AI Bill of Rights

Blueprint for an AI Bill of Rights |  OSTP |  The White House

",blueprint for an ai bill of rights ostp the white house
Lebanon.pdf,7,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 7 of 7

Approved by:  

Section 7.0: Policy & Procedure Revision History

Section

Revisions

Date
12/ 19/ 23

Original Adoption
Amendment
Amendment
Amendment

",page of
Lebanon.pdf,7,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 7 of 7

Approved by:  

Section 7.0: Policy & Procedure Revision History

Section

Revisions

Date
12/ 19/ 23

Original Adoption
Amendment
Amendment
Amendment

",section policy procedure revision history
Lebanon.pdf,7,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 7 of 7

Approved by:  

Section 7.0: Policy & Procedure Revision History

Section

Revisions

Date
12/ 19/ 23

Original Adoption
Amendment
Amendment
Amendment

",section
Lebanon.pdf,7,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 7 of 7

Approved by:  

Section 7.0: Policy & Procedure Revision History

Section

Revisions

Date
12/ 19/ 23

Original Adoption
Amendment
Amendment
Amendment

",revisions
Lebanon.pdf,7,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 7 of 7

Approved by:  

Section 7.0: Policy & Procedure Revision History

Section

Revisions

Date
12/ 19/ 23

Original Adoption
Amendment
Amendment
Amendment

",date
Lebanon.pdf,7,"ADMINISTRATIVE POLICIES &  PROCEDURES

Use of Artificial Intelligence

City of Lebanon
New Hampshire

Policy Number

Effective Date

Last Revision

Page No. 

ADM - 143

12/ 19/ 23

Page 7 of 7

Approved by:  

Section 7.0: Policy & Procedure Revision History

Section

Revisions

Date
12/ 19/ 23

Original Adoption
Amendment
Amendment
Amendment

",original adoption amendment amendment amendment
